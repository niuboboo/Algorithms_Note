{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7043bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418eaf2",
   "metadata": {},
   "source": [
    "## 编解码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d601f5ea",
   "metadata": {},
   "source": [
    "### 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e161355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器结构的基本编码器接口。\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637a96b",
   "metadata": {},
   "source": [
    "### 解码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485ffbf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在下面的解码器接口中，我们新增一个`init_state`函数用于将编码器的输出（`enc_outputs`）转换为编码后的状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a52835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器结构的基本解码器接口。\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386b048",
   "metadata": {},
   "source": [
    "### 合并编码器和解码器\n",
    "\n",
    "&emsp;&emsp;最后，“编码器-解码器”结构包含了一个编码器和一个解码器，并且还拥有可选的额外的参数。在前向传播中，编码器的输出用于生成编码状态，这个状态又被解码器作为其输入的一部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5740cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器结构的基类。\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11164158",
   "metadata": {},
   "source": [
    "## Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a9826f",
   "metadata": {},
   "source": [
    "### 编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a11513",
   "metadata": {},
   "source": [
    "&emsp;&emsp;这里我们采用一层嵌入层(`embedding layer`)来获得输入序列中每个词元的特征向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5b592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 嵌入层，将vocab_size编码为embed_size。\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
    "        \n",
    "    def forward(self, X, *args):\n",
    "        X = self.embedding(X)  # 输出的‘X’的形状：（batch_size, num_steps, embed_size）\n",
    "        \n",
    "        X = X.permute(1, 0, 2) # 在循环神经网络中，默认的是第一个轴对应时间步。\n",
    "        \n",
    "        output, state = self.rnn(X)\n",
    "        # `output`的形状: (`num_steps`, `batch_size`, `num_hiddens`)\n",
    "        # `state[0]`的形状: (`num_layers`, `batch_size`, `num_hiddens`)\n",
    "        \n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e60833",
   "metadata": {},
   "source": [
    "### 解码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85076a2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;实现解码器时，我们可以直接使用编码器最后一个时间步的隐藏状态来初始化解码器的隐藏状态。\n",
    "\n",
    "&emsp;&emsp;如果编解码器是使用循环神经网络实现的话，我们就需要**编码器和解码器具有相同数量的层和隐藏单元**。\n",
    "\n",
    "&emsp;&emsp;为了进一步包含经过编码的输入序列的信息，上下文变量在所有时间步与解码器的输入进行拼接(`concatenate`)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9fa2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
    "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "        # 嵌入层，将vocab_size编码为embed_size。\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # GRU的每个时间步的输入大小为：embed_size + num_hiddens。\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "    \n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        \"\"\"\n",
    "        enc_outputs为(output, state)\n",
    "        \"\"\"\n",
    "        return enc_outputs[1]\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        \"\"\"\n",
    "        X: shape = (`batch_size`, `num_steps`, `embed_size`)\n",
    "        state: shape = (num_layers, batch_size, num_hiddens)\n",
    "        \"\"\"\n",
    "\n",
    "        # 输出'X'的形状：(`batch_size`, `num_steps`, `embed_size`)\n",
    "        X = self.embedding(X)\n",
    "        \n",
    "        # 输出'X'的形状：(`num_steps`, `batch_size`, `embed_size`)\n",
    "        X = X.permute(1, 0, 2) # 在循环神经网络中，默认的是第一个轴对应时间步。\n",
    "        \n",
    "        # 广播‘context’, 使其具有与‘X’相同的‘num_steps’。\n",
    "        context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "        X_and_context = torch.cat((X, context), 2) # shape = (num_steps, batch_size, num_hiddens)\n",
    "        \n",
    "        output, state = self.rnn(X_and_context, state)\n",
    "        # `output`的形状: (`num_steps`, `batch_size`, `num_hiddens`)\n",
    "        # print(output.size())\n",
    "        output = self.dense(output)# .permute(1, 0, 2)\n",
    "        # `output`的形状: (`num_steps`, `batch_size`, `vocab_size`)\n",
    "        \n",
    "        output = output.permute(1, 0, 2)\n",
    "        # `output`的形状: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "        \n",
    "        # `state[0]`的形状: (`num_layers`, `batch_size`, `num_hiddens`)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49685a86",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ded066",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在每个时间步，解码器预测了输出词元的概率分布。\n",
    "\n",
    "&emsp;&emsp;类似于语言模型，可以使用softmax来获得分布，并通过计算交叉熵损失函数来进行优化。\n",
    "\n",
    "&emsp;&emsp;特定的填充词元被添加到序列的末尾，因此不同长度的序列可以以相同形状的小批量加载。但是，应该将填充词元的预测排除在损失函数的计算之外。为此，我们可以使用seqence_mask函数，通过**零值化**屏蔽不相关的项，以便后面任何不相关预测的计算都是与零的乘积，结果都等于零。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a965a4c",
   "metadata": {},
   "source": [
    "#### 序列化Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fed293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"\n",
    "    # 在序列中屏蔽不相关的项。\n",
    "    \"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    \n",
    "    # arange生成下标，然后没行下标小于valid_len中的值为True。\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[None, :] < valid_len[:, None]\n",
    "    \n",
    "    # 取反之后赋值为0。\n",
    "    X[~mask] = value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2add6978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "sequence_mask(X, torch.tensor([1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f5d30",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们还可以使用此函数屏蔽最后几个轴上的所有项。如果愿意，也可以使用指定的非零值来替换这些项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654e8651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.],\n",
       "         [-1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, 4)\n",
    "sequence_mask(X, torch.tensor([1, 2]), value = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49b4b1",
   "metadata": {},
   "source": [
    "#### 带Masked的SoftMax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8c714",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们可以扩展softmax交叉熵损失函数来遮蔽不相关的预测。最初所有预测词元的掩码都设置为1。一旦给定了有效长度，与填充词云对应的掩码将被设置为0。最后，将所有词元的损失乘以掩码，以过滤掉损失中填充词元产生的不相关预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eee0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"\n",
    "    带mask的softmax交叉熵损失函数。\n",
    "    \"\"\"\n",
    "    # pred 的形状：（batch_size, num_steps, vocab_size）\n",
    "    # label 的形状：（batch_size, num_steps）\n",
    "    # valid_len 的形状：（batch_size）\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction = 'none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(pred.permute(0, 2, 1), label)\n",
    "        \n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim = 1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa991f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们可以创建三个相同的序列来进行代码健全性检查，然后分别指定这些序列的有效长度为  4 、 2  和  0 。结果就是，第一个序列的损失应为第二个序列的两倍，而第三个序列的损失应为零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a550fe65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
    "     torch.tensor([4, 2, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2538ed",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1389d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 64, 10\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ed18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size = len(src_vocab), \n",
    "                         embed_size = 32, \n",
    "                         num_hiddens = 32, \n",
    "                         num_layers = 2, \n",
    "                         dropout=0.1)\n",
    "\n",
    "decoder = Seq2SeqDecoder(vocab_size = len(tgt_vocab),\n",
    "                         embed_size = 32, \n",
    "                         num_hiddens = 32, \n",
    "                         num_layers = 2,\n",
    "                         dropout=0.1)\n",
    "\n",
    "def grad_clipping(net, theta):\n",
    "    \"\"\"Clip the gradient.\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "def xavier_init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.GRU:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "\n",
    "lr = 0.005\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "net.apply(xavier_init_weights)\n",
    "net.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "loss = MaskedSoftmaxCELoss()\n",
    "net.train()\n",
    "\n",
    "loss_list = []\n",
    "for epoch in range(300):\n",
    "    for batch in train_iter:\n",
    "        X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "        \n",
    "        # decoder的输入，需要给定一个输入，然后预测下一个词汇。第一个输入是'<bos>', 之后的输入都需要后移。\n",
    "        bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0], device=device).reshape(-1, 1)\n",
    "        \n",
    "        dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 教师强制\n",
    "        \n",
    "        Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l = loss(Y_hat, Y, Y_valid_len)\n",
    "        l.sum().backward()\n",
    "        grad_clipping(net, 1)\n",
    "        num_tokens = Y_valid_len.sum()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss_list.append(l.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e188927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96d6e1",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670b862",
   "metadata": {},
   "source": [
    "&emsp;&emsp;为了采用一个接着一个词元的方式预测出序列，每个解码器当前时间步的输入都将来自于前一时间步的预测词元。\n",
    "\n",
    "&emsp;&emsp;与训练类似，序列开始词元(\"\\<bos>\")在初始时间步被输入到解码器中。当输出序列的预测遇到序列结束词元('\\<eoc>')时，预测就结束了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8f17c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"Truncate or pad sequences.\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列的模型预测\"\"\"\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
    "    \n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    \n",
    "    # 添加批量轴\n",
    "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    \n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    \n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    \n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        \n",
    "        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入。\n",
    "        dec_X = Y.argmax(dim = 2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        \n",
    "        # 保存注意力权重（稍后讨论）\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        \n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        \n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817c1df",
   "metadata": {},
   "source": [
    "## 预测序列的评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261cee3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;用$p_{n}$表示$n$元语法的精确度，它是两个数量的比值:\n",
    "\n",
    "1. 第一个是预测序列与标签序列中匹配的$n$元语法的数量。\n",
    "\n",
    "2. 第二个是预测序列中$n$元语法的数量的比率。\n",
    "\n",
    "&emsp;&emsp;详细解释为：即给定的标签序列$A、B、C、D、E、F$和预测序列$A、B、B、C、D$，我们有$p_{1} = \\frac{4}{5}, p_{2} = \\frac{3}{4}, p_{3} = \\frac{1}{3}$和$p_{4} = 0$。另外，$len_{label}$表示标签序列中的词元数和$len_{pre}$表示预测序列中的词元数。那么，$BLEU$的定义是：\n",
    "\n",
    "$$\n",
    "\\exp \\left(\\min \\left(0,1-\\frac{\\text { len }_{\\text {label }}}{\\text { len }_{\\text {pred }}}\\right)\\right) \\prod_{n=1}^{k} p_{n}^{1 / 2^{n}}\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;其中$k$是用于匹配的最长的$n$元语法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00bfc71",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当预测序列与标签序列完全相同时，`BLEU`为`1`。\n",
    "\n",
    "1. 此外，由于n元语法越长则匹配难度越大，所以BLEU为更长的n元语法的精确度分配更大的权重。具体来说，当$p_{n}$固定时，$p_{n}^{\\frac{1}{2^{n}}}$会随着$n$的增长而增加(原始论文使用$p_{n}^{\\frac{1}{n}}$)。\n",
    "\n",
    "2. 而且，由于预测的序列越短获得的$p_{n}$值越高，所以乘法项之前的系数用于惩罚较短的预测序列。例如，当$k = 2$时，给定标签序列$A、B、C、D、E、F$和预测序列$A、B$，尽管$p_{1} = p_{2} = 1$, 惩罚因子$exp(1 - 6/2) \\sim 0.14$会降低BLEU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b9c2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "# 计算 BLEU\n",
    "def bleu(pred_seq, label_seq, k):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    \n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    # 遍历不同的n-gram。\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):  # 遍历label中的n-gram语法。\n",
    "            label_subs[''.join(label_tokens[i: i + n])] += 1\n",
    "            \n",
    "        for i in range(len_pred - n + 1):  # 遍历预测中的n-gram语法。\n",
    "            if label_subs[''.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1 # 如果发现有，则匹配的数字需要加1。\n",
    "                label_subs[''.join(pred_tokens[i: i + n])] -= 1  # label中的数字需要减去1。\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57062c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va !, bleu 1.000\n",
      "i lost . => j'ai du <unk> pas ?, bleu 0.000\n",
      "he's calm . => il est mouillé <unk> tomber tomber . ! !, bleu 0.343\n",
      "i'm home . => je suis juste !, bleu 0.418\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db5fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c1b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACG",
   "language": "python",
   "name": "acg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
