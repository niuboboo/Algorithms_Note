{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2935802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6512a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ca1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be25e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f719c6d",
   "metadata": {},
   "source": [
    "## 构造特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf182b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.  1. 27.  2.]\n",
      " [25.  2. 32.  1.]]\n"
     ]
    }
   ],
   "source": [
    "feature1 = np.array([[24.,  1., 27.,  2.],\n",
    "                    [25.,  2., 32.,  1.]], dtype=np.float32)\n",
    "print(feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5287b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17544515  0.7042147  -0.3920079  -0.15669443 -0.32453987 -0.11883102\n",
      "   0.21864876 -0.45101166 -0.01959862  0.33695012 -0.56109595 -0.59572214\n",
      "   0.8882939  -0.10159255 -0.08837802  1.5327622   1.2553723  -0.88887525\n",
      "  -0.8803338   0.214064   -0.49087727 -0.7555549   0.08235431 -0.66871864\n",
      "  -1.6715586  -1.5135074  -0.12584263  0.43865064  0.68406886 -1.04486   ]\n",
      " [-0.5781698  -1.023867    1.2425443   0.6189289  -0.57411844 -1.3952923\n",
      "  -0.7495694   0.8037199   0.9653607  -0.74449235  0.3668502   0.7429077\n",
      "  -0.96255165 -0.4425461  -0.24425691 -0.2545424  -1.6711973  -1.3323901\n",
      "  -0.09830271  0.09843035 -0.89755195 -0.1382832  -0.584208   -0.39677384\n",
      "   0.20301136  0.03540502 -1.4764647  -1.4337215  -0.10273612  0.06851932]]\n"
     ]
    }
   ],
   "source": [
    "feature2 = np.random.randn(2, 30).astype(np.float32)\n",
    "print(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fba8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "feature3 = np.array([[1., 0., 0., 1., 0., 1., 0., 1.],\n",
    "                     [0., 1., 0., 1., 0., 1., 0., 1.]], dtype=np.float32)\n",
    "print(feature3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f83d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "feature4 = np.array([[0., 3., 2.]], dtype=np.float32)\n",
    "print(feature4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e38d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature1': array([[24.,  1., 27.,  2.],\n",
      "       [25.,  2., 32.,  1.]], dtype=float32), 'feature2': array([[-0.17544515,  0.7042147 , -0.3920079 , -0.15669443, -0.32453987,\n",
      "        -0.11883102,  0.21864876, -0.45101166, -0.01959862,  0.33695012,\n",
      "        -0.56109595, -0.59572214,  0.8882939 , -0.10159255, -0.08837802,\n",
      "         1.5327622 ,  1.2553723 , -0.88887525, -0.8803338 ,  0.214064  ,\n",
      "        -0.49087727, -0.7555549 ,  0.08235431, -0.66871864, -1.6715586 ,\n",
      "        -1.5135074 , -0.12584263,  0.43865064,  0.68406886, -1.04486   ],\n",
      "       [-0.5781698 , -1.023867  ,  1.2425443 ,  0.6189289 , -0.57411844,\n",
      "        -1.3952923 , -0.7495694 ,  0.8037199 ,  0.9653607 , -0.74449235,\n",
      "         0.3668502 ,  0.7429077 , -0.96255165, -0.4425461 , -0.24425691,\n",
      "        -0.2545424 , -1.6711973 , -1.3323901 , -0.09830271,  0.09843035,\n",
      "        -0.89755195, -0.1382832 , -0.584208  , -0.39677384,  0.20301136,\n",
      "         0.03540502, -1.4764647 , -1.4337215 , -0.10273612,  0.06851932]],\n",
      "      dtype=float32), 'feature3': array([[1., 0., 0., 1., 0., 1., 0., 1.],\n",
      "       [0., 1., 0., 1., 0., 1., 0., 1.]], dtype=float32), 'feature4': array([[0., 3., 2.]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "obs = {'feature1': feature1,\n",
    "       'feature2': feature2,\n",
    "       'feature3': feature3,\n",
    "       'feature4': feature4}\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a856c57b",
   "metadata": {},
   "source": [
    "## 对字典数据进行升维与降维"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880cc16",
   "metadata": {},
   "source": [
    "通常，对于单个样本，我们期望其`batch size`为`1`，所以需要升高一个维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb17f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsqueeze(obs):\n",
    "    if isinstance(obs, dict):\n",
    "        return {k: unsqueeze(v) for k, v in obs.items()}\n",
    "    return obs[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0326a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "(1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(obs['feature1'].shape)\n",
    "print(unsqueeze(obs)['feature1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd126bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(action):\n",
    "    if isinstance(action, dict):\n",
    "        return {k: squeeze(v) for k, v in action.items()}\n",
    "    return np.squeeze(action, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b17a1c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 4)\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(unsqueeze(obs)['feature1'].shape)\n",
    "print(squeeze(unsqueeze(obs))['feature1'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a8ddb",
   "metadata": {},
   "source": [
    "## 将数据转成Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713577a5",
   "metadata": {},
   "source": [
    "在数据经过网络之前，我们期望其能够将数据转换成`Tensor`的格式，所以对于复杂的，像字典包含的数据，我们可以采用如下函数的方式对其进行升维与降维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84dec4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(obj, cuda=True):\n",
    "    if isinstance(obj, list) or isinstance(obj, tuple):\n",
    "        return type(obj)(to_tensor(o, cuda=cuda) for o in obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k : to_tensor(v, cuda=cuda) for k, v in obj.items()}\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return to_tensor(torch.as_tensor(obj), cuda=cuda)\n",
    "    else:\n",
    "        assert isinstance(obj, torch.Tensor) or isinstance(obj, torch.nn.Module)\n",
    "        return obj.cuda() if torch.cuda.is_available() and cuda else obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e92aa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([1, 2], dtype=torch.int32), tensor([3, 4], dtype=torch.int32)]]\n"
     ]
    }
   ],
   "source": [
    "test_data1 = [[np.array([1, 2]), np.array([3, 4])]]\n",
    "print(to_tensor(test_data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef57fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature1': tensor([[24.,  1., 27.,  2.],\n",
      "        [25.,  2., 32.,  1.]]), 'feature2': tensor([[-0.1754,  0.7042, -0.3920, -0.1567, -0.3245, -0.1188,  0.2186, -0.4510,\n",
      "         -0.0196,  0.3370, -0.5611, -0.5957,  0.8883, -0.1016, -0.0884,  1.5328,\n",
      "          1.2554, -0.8889, -0.8803,  0.2141, -0.4909, -0.7556,  0.0824, -0.6687,\n",
      "         -1.6716, -1.5135, -0.1258,  0.4387,  0.6841, -1.0449],\n",
      "        [-0.5782, -1.0239,  1.2425,  0.6189, -0.5741, -1.3953, -0.7496,  0.8037,\n",
      "          0.9654, -0.7445,  0.3669,  0.7429, -0.9626, -0.4425, -0.2443, -0.2545,\n",
      "         -1.6712, -1.3324, -0.0983,  0.0984, -0.8976, -0.1383, -0.5842, -0.3968,\n",
      "          0.2030,  0.0354, -1.4765, -1.4337, -0.1027,  0.0685]]), 'feature3': tensor([[1., 0., 0., 1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1.]]), 'feature4': tensor([[0., 3., 2.]])}\n"
     ]
    }
   ],
   "source": [
    "test_data2 = obs\n",
    "print(to_tensor(obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170404fd",
   "metadata": {},
   "source": [
    "## 字典类型的obs编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d1e9f",
   "metadata": {},
   "source": [
    "先定义一个基础的编码类，能够将不同长度的特征进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c9b46b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1 torch.Size([1, 2, 4])\n",
      "feature2 torch.Size([1, 2, 30])\n",
      "feature3 torch.Size([1, 2, 8])\n",
      "feature4 torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "batch_obs = unsqueeze(obs)\n",
    "batch_obs_tensor = to_tensor(batch_obs)\n",
    "for k, v in batch_obs_tensor.items():\n",
    "    print(k, v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8884e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class VectorEncoder(nn.Module):\n",
    "    def __init__(self, name, input_size, output_size, max_len=None):\n",
    "        super(VectorEncoder, self).__init__()\n",
    "        self.name = name\n",
    "        self.max_len = max_len\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, output_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(output_size, output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c15de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 128\n",
    "encoders = {\n",
    "    'feature1' : VectorEncoder(name = 'feature1', input_size = 4, output_size = feature_size, max_len = 2),\n",
    "    'feature2' : VectorEncoder(name = 'feature2', input_size = 30, output_size = feature_size, max_len = 2),\n",
    "    'feature3' : VectorEncoder(name = 'feature3', input_size = 8, output_size = feature_size, max_len = 2),\n",
    "    'feature4' : VectorEncoder(name = 'feature4', input_size = 3, output_size = feature_size, max_len = 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "801c0339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1 torch.Size([1, 2, 128])\n",
      "feature2 torch.Size([1, 2, 128])\n",
      "feature3 torch.Size([1, 2, 128])\n",
      "feature4 torch.Size([1, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "features = {feature_name : encoder(batch_obs_tensor[feature_name]) for feature_name, encoder in encoders.items()}\n",
    "for k, v in features.items():\n",
    "    print(k, v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce29b19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 3.3870,  0.0000,  2.1932,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           2.3653,  1.4721,  0.0000,  6.1238,  8.7693,  0.0000,  7.3527,\n",
      "           0.0000,  0.0000,  0.3398,  0.6431,  4.4999,  0.0000,  7.5788,\n",
      "           0.0000,  7.9202,  3.0125,  1.8759,  0.0000,  1.9627,  0.7405,\n",
      "           0.0000,  0.0000, 12.3629,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           2.7324,  0.0000,  6.7563,  0.0000,  0.7843,  7.4080,  0.4097,\n",
      "           6.0832,  0.0000,  0.0000,  0.6730,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  5.4909,  0.0000,  0.0000,  2.6584,  0.0000,  0.9764,\n",
      "           0.0000,  5.0096,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.2131,  3.3992,  4.3637,  0.0000,  0.0000,  0.0000,  1.0389,\n",
      "           5.6287,  4.2520,  0.0000,  3.5529,  1.0182,  0.0000,  5.2904,\n",
      "           2.8096,  4.3295,  0.0000,  0.0000,  0.0000,  0.0000,  2.2601,\n",
      "           3.2063,  0.8467,  0.0000,  0.9818,  4.7834,  0.0000,  4.9062,\n",
      "           2.6569,  2.8896,  0.0000,  3.4256,  6.1169,  3.7580,  0.0000,\n",
      "           1.1991,  2.9400,  0.4864,  0.0000,  0.0000,  1.4109,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  1.0570,  2.6655,  3.1332,\n",
      "           0.0000,  5.7646,  0.5895,  0.0000,  0.0000,  0.0000,  0.5789,\n",
      "           3.0296,  0.0000],\n",
      "         [ 3.6517,  0.0000,  2.1746,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           2.4300,  1.9806,  0.0000,  6.8295,  9.4781,  0.0000,  8.3652,\n",
      "           0.0000,  0.0000,  0.4115,  0.3020,  5.4078,  0.0000,  8.0258,\n",
      "           0.0000,  9.0014,  3.9952,  2.2685,  0.0000,  2.4691,  0.9139,\n",
      "           0.0000,  0.0000, 13.7301,  0.0000,  0.0000,  0.0748,  0.0000,\n",
      "           2.7531,  0.0000,  7.7177,  0.0000,  0.4204,  8.1688,  0.1590,\n",
      "           6.7264,  0.0000,  0.0000,  0.9407,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  5.5032,  0.0000,  0.0000,  2.7339,  0.0000,  1.3047,\n",
      "           0.0000,  5.6300,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0687,  4.0988,  4.9686,  0.0000,  0.0000,  0.0000,  1.3158,\n",
      "           6.4798,  4.6761,  0.0000,  3.8955,  1.3813,  0.0000,  6.4067,\n",
      "           2.9157,  4.7582,  0.0000,  0.0000,  0.0000,  0.0000,  2.3715,\n",
      "           3.6674,  1.3617,  0.0000,  1.1060,  5.0359,  0.0000,  5.5078,\n",
      "           2.5055,  3.4877,  0.0000,  3.4783,  6.6074,  4.2474,  0.0000,\n",
      "           1.3010,  3.1722,  0.6608,  0.0000,  0.0000,  1.3077,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  1.4021,  3.5369,  3.4752,\n",
      "           0.0000,  7.0865,  1.0780,  0.0000,  0.0000,  0.0000,  0.9261,\n",
      "           3.3079,  0.0000]]], grad_fn=<ReluBackward0>), tensor([[[0.0000, 0.0190, 0.1586, 0.0000, 0.0000, 0.0000, 0.0336, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1487, 0.1593, 0.1748, 0.0025,\n",
      "          0.0000, 0.0000, 0.0000, 0.2778, 0.0648, 0.0000, 0.1297, 0.0972,\n",
      "          0.0000, 0.0000, 0.0074, 0.0000, 0.0000, 0.0000, 0.0000, 0.1830,\n",
      "          0.3582, 0.0045, 0.1320, 0.0962, 0.0896, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1354,\n",
      "          0.0000, 0.1347, 0.0137, 0.0000, 0.0000, 0.1624, 0.0429, 0.0682,\n",
      "          0.0681, 0.0491, 0.0000, 0.0000, 0.0429, 0.0126, 0.3079, 0.0000,\n",
      "          0.0321, 0.0533, 0.0170, 0.0000, 0.0406, 0.0000, 0.2865, 0.0000,\n",
      "          0.0159, 0.0468, 0.0000, 0.0000, 0.0000, 0.1015, 0.1799, 0.0000,\n",
      "          0.0000, 0.0000, 0.0096, 0.2969, 0.0000, 0.0000, 0.1723, 0.1307,\n",
      "          0.1321, 0.0743, 0.3558, 0.1518, 0.0000, 0.0000, 0.3415, 0.0658,\n",
      "          0.0000, 0.0000, 0.0327, 0.0913, 0.2182, 0.0000, 0.0000, 0.0000,\n",
      "          0.1555, 0.1144, 0.0000, 0.0054, 0.0000, 0.0000, 0.0000, 0.1390,\n",
      "          0.0456, 0.0000, 0.0262, 0.0000, 0.0000, 0.1651, 0.0000, 0.0665,\n",
      "          0.0140, 0.2979, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1634, 0.3015, 0.0000, 0.0000, 0.0986, 0.2936, 0.0211,\n",
      "          0.0000, 0.0000, 0.1340, 0.0000, 0.0000, 0.0000, 0.1239, 0.0662,\n",
      "          0.0147, 0.0000, 0.3764, 0.3287, 0.0000, 0.0108, 0.1113, 0.0000,\n",
      "          0.0000, 0.5105, 0.0000, 0.1982, 0.0000, 0.0000, 0.0000, 0.0765,\n",
      "          0.0665, 0.0000, 0.0000, 0.3526, 0.0288, 0.0000, 0.0537, 0.0000,\n",
      "          0.0000, 0.0432, 0.0000, 0.2762, 0.1844, 0.0000, 0.0205, 0.2165,\n",
      "          0.1498, 0.1731, 0.2669, 0.0000, 0.0000, 0.0115, 0.0146, 0.1608,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1835, 0.0000, 0.4953, 0.1754,\n",
      "          0.0221, 0.0000, 0.3799, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1751, 0.0000, 0.1542, 0.0000, 0.2477, 0.1551, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2423, 0.1686,\n",
      "          0.0460, 0.0000, 0.0000, 0.3082, 0.0000, 0.1967, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.2925, 0.1526, 0.0000, 0.0211, 0.0000,\n",
      "          0.2726, 0.0000, 0.0000, 0.0744, 0.0061, 0.0000, 0.1032, 0.1670,\n",
      "          0.2795, 0.3678, 0.0000, 0.0000, 0.3587, 0.0199, 0.0000, 0.0000,\n",
      "          0.0000, 0.3057, 0.1364, 0.5161, 0.0612, 0.0000, 0.0000, 0.0000]]],\n",
      "       grad_fn=<ReluBackward0>), tensor([[[0.2424, 0.2257, 0.0421, 0.0000, 0.0219, 0.0000, 0.0000, 0.2757,\n",
      "          0.0459, 0.0000, 0.0000, 0.0000, 0.0313, 0.0000, 0.0000, 0.0000,\n",
      "          0.0999, 0.0000, 0.0000, 0.1299, 0.0000, 0.3294, 0.1093, 0.2182,\n",
      "          0.0000, 0.0000, 0.0000, 0.0108, 0.0000, 0.0000, 0.0418, 0.1606,\n",
      "          0.2395, 0.0000, 0.0105, 0.2244, 0.0961, 0.0000, 0.2599, 0.0000,\n",
      "          0.0000, 0.3506, 0.0000, 0.0631, 0.2993, 0.1582, 0.0000, 0.2938,\n",
      "          0.0000, 0.1704, 0.0000, 0.1230, 0.0190, 0.0000, 0.1251, 0.1055,\n",
      "          0.0000, 0.0781, 0.0603, 0.0000, 0.2561, 0.0000, 0.0000, 0.1514,\n",
      "          0.0000, 0.0000, 0.0000, 0.0892, 0.1692, 0.0703, 0.0051, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1260, 0.0000, 0.0403, 0.0660,\n",
      "          0.0713, 0.0824, 0.2193, 0.0000, 0.0000, 0.0267, 0.0288, 0.3096,\n",
      "          0.0000, 0.0000, 0.0000, 0.1881, 0.0727, 0.1926, 0.0000, 0.0000,\n",
      "          0.0000, 0.1805, 0.0000, 0.0000, 0.0000, 0.0000, 0.1943, 0.0000,\n",
      "          0.1000, 0.0000, 0.0000, 0.0110, 0.3408, 0.0497, 0.0443, 0.0000,\n",
      "          0.1095, 0.2232, 0.5288, 0.2494, 0.2242, 0.0827, 0.0963, 0.1617,\n",
      "          0.0000, 0.0000, 0.0877, 0.2691, 0.0622, 0.2125, 0.0860, 0.1095],\n",
      "         [0.1026, 0.1070, 0.1777, 0.0000, 0.0527, 0.0000, 0.0000, 0.0113,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2231, 0.0000, 0.0000, 0.1144, 0.0000, 0.1985, 0.0917, 0.2154,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1470, 0.1432,\n",
      "          0.2769, 0.0000, 0.1027, 0.1924, 0.1350, 0.0306, 0.2915, 0.0469,\n",
      "          0.0000, 0.3567, 0.0910, 0.0301, 0.0000, 0.0162, 0.0000, 0.2961,\n",
      "          0.0000, 0.2426, 0.0000, 0.0000, 0.0000, 0.0000, 0.2792, 0.1212,\n",
      "          0.0000, 0.0566, 0.0000, 0.0000, 0.2930, 0.0000, 0.2010, 0.1444,\n",
      "          0.0000, 0.0503, 0.0000, 0.1185, 0.1957, 0.2313, 0.0000, 0.0773,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1566, 0.0000, 0.0140, 0.0058,\n",
      "          0.0819, 0.0000, 0.0850, 0.0000, 0.0000, 0.1386, 0.0481, 0.2451,\n",
      "          0.0521, 0.0000, 0.0000, 0.0000, 0.2872, 0.0373, 0.0000, 0.0000,\n",
      "          0.1744, 0.1442, 0.0000, 0.0000, 0.0000, 0.0000, 0.2868, 0.0439,\n",
      "          0.0193, 0.0494, 0.0000, 0.0922, 0.3627, 0.0103, 0.0000, 0.0000,\n",
      "          0.1286, 0.2390, 0.5612, 0.2265, 0.0401, 0.2231, 0.0216, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.3117, 0.1687, 0.1607, 0.0037, 0.1901]]],\n",
      "       grad_fn=<ReluBackward0>), tensor([[[0.0000, 0.4914, 0.0000, 0.0000, 0.0596, 0.1546, 0.3470, 0.0000,\n",
      "          0.0000, 1.1842, 0.2933, 0.3166, 0.6674, 0.8855, 0.6146, 0.0000,\n",
      "          0.2028, 0.1623, 0.1371, 0.0000, 0.0000, 0.2413, 0.0000, 0.0000,\n",
      "          0.1763, 0.1122, 1.2377, 0.9525, 0.7891, 0.0398, 0.7062, 0.0000,\n",
      "          0.0000, 0.3662, 0.0000, 0.4877, 0.5616, 0.0000, 0.0000, 0.0981,\n",
      "          0.0329, 0.6726, 0.0000, 0.0000, 0.0000, 0.2716, 0.9323, 0.0000,\n",
      "          0.7020, 0.0000, 0.3835, 0.0000, 0.0565, 0.0000, 0.0348, 0.5019,\n",
      "          0.1468, 0.6745, 0.0000, 0.0000, 0.8479, 0.0000, 0.0000, 0.4344,\n",
      "          0.3660, 0.4340, 0.0000, 0.2862, 0.8727, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5100, 0.0652, 0.0000, 0.7327, 0.2711, 0.0119, 0.0000,\n",
      "          0.0000, 0.3692, 0.0000, 0.0497, 1.0908, 0.0000, 0.4031, 0.0000,\n",
      "          1.2751, 0.0000, 0.5717, 0.0000, 1.0221, 0.0000, 0.2228, 0.0000,\n",
      "          0.4274, 0.0000, 0.4424, 0.4929, 0.0000, 0.2747, 0.0000, 0.1674,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0120, 0.2892,\n",
      "          0.0000, 0.0000, 0.0000, 0.3105, 0.0000, 0.3812, 0.0000, 0.0000,\n",
      "          0.5072, 0.0000, 0.0190, 0.2779, 0.0000, 0.3030, 0.0354, 0.4288]]],\n",
      "       grad_fn=<ReluBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "print(list(features.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ecb93",
   "metadata": {},
   "source": [
    "特征独立编码到同一维度之后可以考虑将其`cat`在一起："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0cca2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 128])\n"
     ]
    }
   ],
   "source": [
    "feature_seq = torch.cat(list(features.values()), dim=1)\n",
    "print(feature_seq.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040fd15",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc235b5",
   "metadata": {},
   "source": [
    "`Transformer`为主体网络结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "785959d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttentionImp(torch.nn.MultiheadAttention):\n",
    "    def forward(self, query, key, value, key_padding_mask=None, need_weights=True, attn_mask=None):\n",
    "        attn_output, self.attn_output_weights = super().forward(query, key, value, key_padding_mask, need_weights, attn_mask)\n",
    "        return attn_output, self.attn_output_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebc04945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class TransformerEncoderLayerImp(torch.nn.TransformerEncoderLayer):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=F.relu, layer_norm_eps=1e-5, batch_first=False, norm_first=False, device=None, dtype=None) -> None:\n",
    "        super().__init__(d_model, nhead, dim_feedforward, dropout, activation, layer_norm_eps, batch_first, norm_first, device, dtype)\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        self.self_attn = MultiheadAttentionImp(d_model, nhead, dropout=dropout, batch_first=batch_first, **factory_kwargs)\n",
    "\n",
    "    # self-attention block\n",
    "    def _sa_block(self, x, attn_mask, key_padding_mask):\n",
    "        x = self.self_attn(x, x, x, attn_mask=attn_mask, key_padding_mask=key_padding_mask, need_weights=True)[0]\n",
    "        return self.dropout1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57eb10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_layer = torch.nn.TransformerEncoder(\n",
    "                    TransformerEncoderLayerImp(feature_size, nhead=4, dim_feedforward=feature_size, batch_first=True, dropout=0),\n",
    "                    num_layers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70948086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 128])\n"
     ]
    }
   ],
   "source": [
    "feature_seq = transformer_layer(feature_seq)\n",
    "print(feature_seq.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5406a3",
   "metadata": {},
   "source": [
    "同样可以获取到`Transformer`最后一层输出的`attention weight`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2633d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1891, 0.1906, 0.1218, 0.1229, 0.1257, 0.1205, 0.1294],\n",
      "         [0.1903, 0.1917, 0.1210, 0.1224, 0.1251, 0.1200, 0.1294],\n",
      "         [0.1682, 0.1707, 0.1285, 0.1365, 0.1335, 0.1228, 0.1398],\n",
      "         [0.1706, 0.1734, 0.1253, 0.1333, 0.1330, 0.1217, 0.1426],\n",
      "         [0.1782, 0.1809, 0.1230, 0.1293, 0.1297, 0.1201, 0.1389],\n",
      "         [0.1746, 0.1773, 0.1253, 0.1313, 0.1310, 0.1214, 0.1391],\n",
      "         [0.1730, 0.1769, 0.1276, 0.1332, 0.1300, 0.1202, 0.1391]]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(transformer_layer.layers[-1].self_attn.attn_output_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7237985",
   "metadata": {},
   "source": [
    "## enhance_fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe2f3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe27d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3e1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90a1e04b",
   "metadata": {},
   "source": [
    "## learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d593eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
