{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf43cec",
   "metadata": {},
   "source": [
    "## 批量归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae62778",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在神经网络反向传播的过程中，由于损失出现在后面，后面几层的训练是会比较快的。而靠近数据层的训练是比较慢的，这样在靠近数据层的权重发生变化的时候，靠近输出层的网络权重就需要重新训练，会导致收敛变慢。\n",
    "\n",
    "&emsp;&emsp;**那我们可以在学习底部层的时候，避免顶部层的变化吗？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7b224",
   "metadata": {},
   "source": [
    "&emsp;&emsp;批量归一化，说的是在`mini-batch`数据输入的时候，在不同层的不同地方的`mini-batch`，它的均值和方差给固定住。\n",
    "\n",
    "$$\n",
    "\\mu_{B}=\\frac{1}{|B|} \\sum_{i \\in B} x_{i} \\text { and } \\sigma_{B}^{2}=\\frac{1}{|B|} \\sum_{i \\in B}\\left(x_{i}-\\mu_{B}\\right)^{2}+\\epsilon\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;对所有样本求和，再除以批量大小，得到均值。方差就是数据减去均值的平方再除以批量大小数，最后再加上一个很小的数，防止变为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1847ba24",
   "metadata": {},
   "source": [
    "&emsp;&emsp;批量归一化，就是将所有的输入样本做如下处理:\n",
    "\n",
    "$$\n",
    "x_{i+1}=\\gamma \\frac{x_{i}-\\mu_{B}}{\\sigma_{B}}+\\beta\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;其中$\\gamma$和$\\beta$是可学习参数。来使得加权之后的均值和方差对网络更加好一点，但是会限制$\\gamma$和$\\beta$的变化，使其变化地不要过于猛烈。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1db591d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;批量归一化可以作用在\n",
    "\n",
    "1. 全连接层和卷积层的输出上，激活函数前; 批量归一化做的是线性变换，激活函数做的是非线性变换。\n",
    "2. 全连接层和卷积层的输入上;\n",
    "\n",
    "&emsp;&emsp;对于全连接层，批量归一化作用的是在特征维度，与在数据层面做归一化类似，但是这里是对卷积层和全连接层的每一层输入输出都做这样的事情，而不是只作用在数据上。之后再用学习到的参数$\\gamma$和$\\beta$再对其做一次校验。\n",
    "\n",
    "&emsp;&emsp;对于卷积层，作用的是在通道维度上。假设通道数为100的话，那么对于一个像素来说，你可以认为这个向量是这个像素的一个特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d248a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;批量归一化最初的论文是想用它来减少内部协变量的转移，\n",
    "\n",
    "&emsp;&emsp;后续有论文指出它可能就是通过在每个小批量里加入噪音来控制模型复杂度，因为每个小批量的均值和方差都是在随机变动的。从这个控制模型复杂度角度理解的话，就没有必要和丢弃法混合使用了。\n",
    "\n",
    "&emsp;&emsp;批量归一化可以加速收敛速度，但一般不改变模型精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651da5a7",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed330619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8ceda",
   "metadata": {},
   "source": [
    "### batch_norm核心公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b25db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    \"\"\"\n",
    "    moving_mean: 整个数据集上的均值。\n",
    "    moving_var: 整个数据集上的方差。\n",
    "    eps: 是一个为了避免除0的东西。\n",
    "    momentum: 用于更新moving_mean和moving_var的东西。\n",
    "    \"\"\"\n",
    "    if not torch.is_grad_enabled():  # 在做inference的时候，减去全局的均值和方差。\n",
    "        # 可能只有一张图片，所以不用在这个batch上做归一化。\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        # 确定这里要么是一个全连接层(len(X.shape)=2)，要么是一个2D的卷积(len(X.shape)=4)。\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X-mean)**2).mean(dim=0)\n",
    "        else:\n",
    "            # 按照通道数来求均值，对里面每一个通道的所有批量，所有高宽来求均值。\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True) # 结果是一个 1xNx1x1 这样一个4D的东西。\n",
    "            var = ((X - mean)**2).mean(dim=(0, 2, 3), keepdim=True) # 结果是一个 1xNx1x1 这样一个4D的东西。\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        \n",
    "        # 更新全局的均值。并且只是在训练的过程中去做这样一个更新，做推理的时候并不做这样一个更新。\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d492970d",
   "metadata": {},
   "source": [
    "### batch_norm层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a565bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        num_features: 特征的个数。\n",
    "        num_dims: 维度，这里简单起见，要么是2，要么是4。\n",
    "        \"\"\"\n",
    "        # 获取shape维度，方便之后创建变量。\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(X, self.gamma, self.beta, self.moving_mean,\n",
    "                                                         self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d517adcf",
   "metadata": {},
   "source": [
    "### batch_norm用于LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81c6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(16*4*4, 120), BatchNorm(120, num_dims=2), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0156bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Out Put Shape:  torch.Size([1, 6, 24, 24])\n",
      "BatchNorm Out Put Shape:  torch.Size([1, 6, 24, 24])\n",
      "Sigmoid Out Put Shape:  torch.Size([1, 6, 24, 24])\n",
      "AvgPool2d Out Put Shape:  torch.Size([1, 6, 12, 12])\n",
      "Conv2d Out Put Shape:  torch.Size([1, 16, 8, 8])\n",
      "BatchNorm Out Put Shape:  torch.Size([1, 16, 8, 8])\n",
      "Sigmoid Out Put Shape:  torch.Size([1, 16, 8, 8])\n",
      "AvgPool2d Out Put Shape:  torch.Size([1, 16, 4, 4])\n",
      "Flatten Out Put Shape:  torch.Size([1, 256])\n",
      "Linear Out Put Shape:  torch.Size([1, 120])\n",
      "BatchNorm Out Put Shape:  torch.Size([1, 120])\n",
      "Sigmoid Out Put Shape:  torch.Size([1, 120])\n",
      "Linear Out Put Shape:  torch.Size([1, 84])\n",
      "BatchNorm Out Put Shape:  torch.Size([1, 84])\n",
      "Sigmoid Out Put Shape:  torch.Size([1, 84])\n",
      "Linear Out Put Shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, \"Out Put Shape: \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "707e2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    \n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "        \n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\", train=False, transform=trans, download=True)\n",
    "    \n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47257147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tinyzqh/miniforge3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-wdh4qigd/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1685dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b82984",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
    "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
    "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = argmax(y_hat, axis=1)\n",
    "    cmp = astype(y_hat, y.dtype) == y\n",
    "    return float(reduce_sum(astype(cmp, y.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4431c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "        if not device: # 如果没有指定device, 就用网络参数中的所给定的那个device。\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    metric = Accumulator(2)\n",
    "    \n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X, list):\n",
    "            X = [x.to(device) for x in X]  # 将数据挪到device上。\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "            \n",
    "        y = y.to(device)\n",
    "        \n",
    "        metric.add(accuracy(net(X), y), y.numel())\n",
    "        \n",
    "        return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f38b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    net.apply(init_weights)  # 对net里面的每一个parameter都去run一下init_weights这个函数。\n",
    "    print(\"trainng on {}\".format(device))\n",
    "    \n",
    "    net.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    num_batches = len(train_iter)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y_hat = net(X)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
    "            \n",
    "            train_loss = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            \n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                print(\"epoch {}, train_loss {}, train_acc {}\".format(epoch + (i + 1) / num_batches, \n",
    "                                                                  train_loss, train_acc))\n",
    "    test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "    print(f'loss {train_loss:.3f}, train acc {train_acc:.3f}, 'f'test acc {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a1c5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "208fd093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainng on cpu\n",
      "epoch 0.2, train_loss 1.1157996844738087, train_acc 0.6095412234042553\n",
      "epoch 0.4, train_loss 0.919659712213151, train_acc 0.6742021276595744\n",
      "epoch 0.6, train_loss 0.8318415930930604, train_acc 0.7018783244680851\n",
      "epoch 0.8, train_loss 0.7667046658536221, train_acc 0.7247755984042553\n",
      "epoch 1.0, train_loss 0.7192401525497436, train_acc 0.7416\n",
      "epoch 1.2, train_loss 0.5064855338411128, train_acc 0.8115857712765957\n",
      "epoch 1.4, train_loss 0.48988876729569536, train_acc 0.820063164893617\n",
      "epoch 1.6, train_loss 0.4825343162032729, train_acc 0.8231105939716312\n",
      "epoch 1.8, train_loss 0.47760752176350735, train_acc 0.8243018617021277\n",
      "epoch 2.0, train_loss 0.4683734359105428, train_acc 0.8284666666666667\n",
      "epoch 2.2, train_loss 0.4082371751044659, train_acc 0.8485704787234043\n",
      "epoch 2.4, train_loss 0.40830606127038915, train_acc 0.8496509308510638\n",
      "epoch 2.6, train_loss 0.41287886969586635, train_acc 0.8478224734042553\n",
      "epoch 2.8, train_loss 0.4081670050608351, train_acc 0.8491730385638298\n",
      "epoch 3.0, train_loss 0.4020807728767395, train_acc 0.8520666666666666\n",
      "epoch 3.2, train_loss 0.3728638969837351, train_acc 0.8623670212765957\n",
      "epoch 3.4, train_loss 0.3748479770853164, train_acc 0.8636552526595744\n",
      "epoch 3.6, train_loss 0.3719556968896947, train_acc 0.8645002216312057\n",
      "epoch 3.8, train_loss 0.3690693812008868, train_acc 0.8656914893617021\n",
      "epoch 4.0, train_loss 0.36756012236277263, train_acc 0.8663\n",
      "epoch 4.2, train_loss 0.3388371594408725, train_acc 0.8769946808510638\n",
      "epoch 4.4, train_loss 0.34374764783585326, train_acc 0.8758311170212766\n",
      "epoch 4.6, train_loss 0.3417847517957079, train_acc 0.8768284574468085\n",
      "epoch 4.8, train_loss 0.33694583042821985, train_acc 0.8784906914893617\n",
      "epoch 5.0, train_loss 0.33926119248072306, train_acc 0.8768166666666667\n",
      "epoch 5.2, train_loss 0.32243611616023043, train_acc 0.8800698138297872\n",
      "epoch 5.4, train_loss 0.3211827690296985, train_acc 0.8813164893617021\n",
      "epoch 5.6, train_loss 0.32208142181237537, train_acc 0.8812887854609929\n",
      "epoch 5.8, train_loss 0.3195616457849107, train_acc 0.8821476063829787\n",
      "epoch 6.0, train_loss 0.318551148223877, train_acc 0.8834\n",
      "epoch 6.2, train_loss 0.31086648176325127, train_acc 0.8848071808510638\n",
      "epoch 6.4, train_loss 0.30632585667549295, train_acc 0.8882978723404256\n",
      "epoch 6.6, train_loss 0.3023616193879581, train_acc 0.8885472074468085\n",
      "epoch 6.8, train_loss 0.30345205273082915, train_acc 0.8879862034574468\n",
      "epoch 7.0, train_loss 0.30334592469533284, train_acc 0.8879833333333333\n",
      "epoch 7.2, train_loss 0.2794762323511408, train_acc 0.895279255319149\n",
      "epoch 7.4, train_loss 0.28884028944563356, train_acc 0.8922872340425532\n",
      "epoch 7.6, train_loss 0.2899449015340061, train_acc 0.8915669326241135\n",
      "epoch 7.8, train_loss 0.28880422594065364, train_acc 0.8929521276595744\n",
      "epoch 8.0, train_loss 0.29035710678100585, train_acc 0.8927\n",
      "epoch 8.2, train_loss 0.2811564929941867, train_acc 0.8961934840425532\n",
      "epoch 8.4, train_loss 0.2800549969394156, train_acc 0.8961934840425532\n",
      "epoch 8.6, train_loss 0.27787854844796744, train_acc 0.8977449024822695\n",
      "epoch 8.8, train_loss 0.27759696765148895, train_acc 0.8978349401595744\n",
      "epoch 9.0, train_loss 0.2783068033218384, train_acc 0.8971\n",
      "epoch 9.2, train_loss 0.2710125116591758, train_acc 0.9010139627659575\n",
      "epoch 9.4, train_loss 0.26826724124715684, train_acc 0.901845079787234\n",
      "epoch 9.6, train_loss 0.27021240997821727, train_acc 0.900072030141844\n",
      "epoch 9.8, train_loss 0.26987353989735563, train_acc 0.8999542885638298\n",
      "epoch 10.0, train_loss 0.27028704369862877, train_acc 0.9001666666666667\n",
      "loss 0.270, train acc 0.900, test acc 0.906\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.9, 10\n",
    "train(net, train_iter, test_iter, num_epochs, lr, try_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82966c56",
   "metadata": {},
   "source": [
    "### 拉伸参数gamma和偏移参数beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f07198ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8035, 2.9319, 2.7292, 4.4260, 2.3077, 2.6277],\n",
       "        grad_fn=<ViewBackward>),\n",
       " tensor([-0.7501, -1.6460, -2.9647,  2.4097,  1.4707, -2.0397],\n",
       "        grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1].gamma.reshape((-1,)), net[1].beta.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e860a",
   "metadata": {},
   "source": [
    "## 简明实现\n",
    "\n",
    "&emsp;&emsp;简明实现就是调用`nn.BatchNorm2d`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "900f6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63ac1622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainng on cpu\n",
      "epoch 0.2, train_loss 1.0844372206545891, train_acc 0.6171875\n",
      "epoch 0.4, train_loss 0.8916318369038562, train_acc 0.6798952792553191\n",
      "epoch 0.6, train_loss 0.8001158011297808, train_acc 0.711436170212766\n",
      "epoch 0.8, train_loss 0.7445767458449019, train_acc 0.7301155252659575\n",
      "epoch 1.0, train_loss 0.703881033706665, train_acc 0.7449\n",
      "epoch 1.2, train_loss 0.5291786510893639, train_acc 0.8035239361702128\n",
      "epoch 1.4, train_loss 0.5035403221845627, train_acc 0.8138713430851063\n",
      "epoch 1.6, train_loss 0.49055850907420434, train_acc 0.8199523492907801\n",
      "epoch 1.8, train_loss 0.478026808100812, train_acc 0.8243641954787234\n",
      "epoch 2.0, train_loss 0.46913920974731443, train_acc 0.8276666666666667\n",
      "epoch 2.2, train_loss 0.42546047492230193, train_acc 0.8426695478723404\n",
      "epoch 2.4, train_loss 0.41432177861954306, train_acc 0.8472822473404256\n",
      "epoch 2.6, train_loss 0.40768800538482397, train_acc 0.8503435283687943\n",
      "epoch 2.8, train_loss 0.40304638699014134, train_acc 0.8524559507978723\n",
      "epoch 3.0, train_loss 0.39893745981852213, train_acc 0.8544833333333334\n",
      "epoch 3.2, train_loss 0.3743186355271238, train_acc 0.8646941489361702\n",
      "epoch 3.4, train_loss 0.3697584143027346, train_acc 0.8660654920212766\n",
      "epoch 3.6, train_loss 0.3695710674456671, train_acc 0.8653313386524822\n",
      "epoch 3.8, train_loss 0.3641555265701832, train_acc 0.8673121675531915\n",
      "epoch 4.0, train_loss 0.35985086612701417, train_acc 0.86885\n",
      "epoch 4.2, train_loss 0.3397889717462215, train_acc 0.8753324468085106\n",
      "epoch 4.4, train_loss 0.34612147335676435, train_acc 0.8725897606382979\n",
      "epoch 4.6, train_loss 0.34169599804895145, train_acc 0.8746398492907801\n",
      "epoch 4.8, train_loss 0.3391512285997259, train_acc 0.875748005319149\n",
      "epoch 5.0, train_loss 0.33383863131205244, train_acc 0.8780166666666667\n",
      "epoch 5.2, train_loss 0.3231771065199629, train_acc 0.8821476063829787\n",
      "epoch 5.4, train_loss 0.32297644272763676, train_acc 0.8813996010638298\n",
      "epoch 5.6, train_loss 0.3210664879768453, train_acc 0.8818705673758865\n",
      "epoch 5.8, train_loss 0.320746927423046, train_acc 0.8818567154255319\n",
      "epoch 6.0, train_loss 0.3150538609822591, train_acc 0.8842\n",
      "epoch 6.2, train_loss 0.3063108718141596, train_acc 0.8858876329787234\n",
      "epoch 6.4, train_loss 0.3007509098091024, train_acc 0.8893783244680851\n",
      "epoch 6.6, train_loss 0.3000143232709127, train_acc 0.8900986258865248\n",
      "epoch 6.8, train_loss 0.3008782646440445, train_acc 0.8888380984042553\n",
      "epoch 7.0, train_loss 0.3004761568069458, train_acc 0.88915\n",
      "epoch 7.2, train_loss 0.28191622489310325, train_acc 0.8970246010638298\n",
      "epoch 7.4, train_loss 0.2857509802313561, train_acc 0.8957779255319149\n",
      "epoch 7.6, train_loss 0.2848713797457675, train_acc 0.8945866578014184\n",
      "epoch 7.8, train_loss 0.2860942858647793, train_acc 0.8938248005319149\n",
      "epoch 8.0, train_loss 0.28466767082214356, train_acc 0.8946666666666667\n",
      "epoch 8.2, train_loss 0.2809956019863169, train_acc 0.8966090425531915\n",
      "epoch 8.4, train_loss 0.27664622949792983, train_acc 0.8987699468085106\n",
      "epoch 8.6, train_loss 0.2750257099351139, train_acc 0.8992132092198581\n",
      "epoch 8.8, train_loss 0.2766993673557931, train_acc 0.8988946143617021\n",
      "epoch 9.0, train_loss 0.2754461384455363, train_acc 0.8990333333333334\n",
      "epoch 9.2, train_loss 0.2832746258441438, train_acc 0.8931183510638298\n",
      "epoch 9.4, train_loss 0.2715207175054449, train_acc 0.8990192819148937\n",
      "epoch 9.6, train_loss 0.26844596270973803, train_acc 0.9008477393617021\n",
      "epoch 9.8, train_loss 0.2701458701903516, train_acc 0.899642619680851\n",
      "epoch 10.0, train_loss 0.26765803578694664, train_acc 0.9007333333333334\n",
      "loss 0.268, train acc 0.901, test acc 0.605\n"
     ]
    }
   ],
   "source": [
    "train(net, train_iter, test_iter, num_epochs, lr, try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63992e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
