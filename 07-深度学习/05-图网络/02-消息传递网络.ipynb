{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610551a9",
   "metadata": {},
   "source": [
    "## 消息传递网络\n",
    "\n",
    "&emsp;&emsp;将卷积神经网络中的“卷积算子”应用到图上面，核心在于neighborhood aggregation机制，或者说是message passing的机制。Aggregate Neighbours，核心思想在于基于局部网络连接来生成Node embeddings（Generate node embeddings based on local network neighborhoods）。如下面这个图：\n",
    "\n",
    "<img src=\"../../images/12-graph_message_pass.png\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3087fdf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;例如图中节点A的embedding决定于其邻居节点$\\{B, C, D\\}$，而这些节点又受到它们各自的邻居节点的影响。\n",
    "\n",
    "&emsp;&emsp;图中的“黑箱”可以看成是整合其邻居节点信息的操作，它有一个很重要的属性——其操作应该是顺序（order invariant）无关的，如求和、求平均、求最大值这样的操作，可以采用神经网络来获取。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd657274",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Layer-0节点$\\mu$的embedding是其节点特征向量$x_{\\mu}$。例如Layer-1中B节点的mebedding就由Layer-0中节点A的特征向量$x_{A}$和节点$C$的特征向量$X_{C}$经过神经网络计算得到:\n",
    "\n",
    "<img src=\"../../images/12-graph_message_pass_1.png\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e06793",
   "metadata": {},
   "source": [
    "&emsp;&emsp;也就是说，对于第$k$层的节点$i$来说，它的特征向量$x_{i}^{(k)}$就是:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{i}^{(k)}=\\gamma^{(k)}\\left(\\mathbf{x}_{i}^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\phi^{(k)}\\left(\\mathbf{x}_{i}^{(k-1)}, \\mathbf{x}_{j}^{(k-1)}, \\mathbf{e}_{j, i}\\right)\\right)\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;其中$x_{i}^{(k-1)} \\in \\mathbb{R}^{D}$是节点$i$第$k-1$层的特征向量；$e_{j, i} \\in \\mathbb{R}^{D}$为从节点$j$到节点$i$的边的特征向量，$\\square$为一个可微的、置换不变的函数，表示聚合`aggregation`函数；$\\gamma$表示`update`函数；$\\phi$message函数，为其他的可微函数，比如像多层感知机`MLP`等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb25ab5",
   "metadata": {},
   "source": [
    "## 消息传递基类\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba31ca3",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`PyTorch Geometric`提供了基本类`MessagePassing`，可以实现上述的图神经网络，来实现消息传递或消息聚集:\n",
    "\n",
    "1. `MessagePassing(aggr=\"add\", flow=\"source_to_target\", node_dim=-2)`: \n",
    "\n",
    "    - aggr: 指定采用的置换不变函数，默认是add，可以定义为add、mean、max和None。\n",
    "    - flow: 指定信息传递的反向，默认是source_to_target，还可以设置为target_to_source。\n",
    "\n",
    "2. `MessagePassing.propagate(edge_index, size=None, **kwargs)`: \n",
    "\n",
    "3. `MessagePassing.message(...)`:\n",
    "\n",
    "    - 这个函数定义了对于每个节点对$(x_{i}, x_{j})$，怎样生成信息(message)。\n",
    "\n",
    "4. `MessagePassing.update(aggr_out, ...)`:\n",
    "\n",
    "    - 这个函数利用聚合好的信息(message)更新每个节点的embedding。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe167277",
   "metadata": {},
   "source": [
    "## 实战GCN层\n",
    "\n",
    "&emsp;&emsp;`GCN`在数学上的定义为:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{i}^{(k)}=\\sum_{j \\in \\mathcal{N}(i) \\cup\\{i\\}} \\frac{1}{\\sqrt{\\operatorname{deg}(i)} \\cdot \\sqrt{\\operatorname{deg}(j)}} \\cdot\\left(\\boldsymbol{\\Theta} \\cdot \\mathbf{x}_{j}^{(k-1)}\\right)\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;通过权值矩阵对相邻节点特征$\\boldsymbol{\\Theta}$进行变换，按照两个节点$i$和$j$的度进行标准化，然后求和，得到这一层节点$i$的`embedding`向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ac88a",
   "metadata": {},
   "source": [
    "1. **Add self-loops to the adjacency matrix**：主要通过`torch_geometric.utils.add_self_loops`方法实现。这一步相当于是对邻接矩阵的预处理，即增加节点的自身循环。\n",
    "\n",
    "<img src=\"../../images/12-graph_example1.png\" width=\"40%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae28b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size: \n",
      "torch.Size([3, 1])\n",
      "original edge_index\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "new edge_index\n",
      "tensor([[0, 1, 1, 2, 0, 1, 2],\n",
      "        [1, 0, 2, 1, 0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "# 由于是无向图，因此有 4 条边：(0 -> 1), (1 -> 0), (1 -> 2), (2 -> 1)\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "# 节点的特征                           \n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "print(\"x.size: \")\n",
    "print(x.size())\n",
    "\n",
    "print(\"original edge_index\")\n",
    "print(edge_index)\n",
    "\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "print(\"new edge_index\")\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c30d67c",
   "metadata": {},
   "source": [
    "2. **Linearly transform node feature matrix**: 第二步是对节点的特征矩阵进行线性变换。主要通过一个线性层`torch.nn.Linear`实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c153588",
   "metadata": {},
   "source": [
    "3. **Compute normalization coefficients**: 第三步是对变换后的节点特征进行标准化。节点的度可以通过`torch_geometric.utils.degree`实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb86044a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original edge_index \n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "new edge_index\n",
      "tensor([[0, 1, 1, 2, 0, 1, 2],\n",
      "        [1, 0, 2, 1, 0, 1, 2]])\n",
      "row, col is :\n",
      "tensor([0, 1, 1, 2, 0, 1, 2]) tensor([1, 0, 2, 1, 0, 1, 2])\n",
      "deg is :\n",
      "tensor([2., 3., 2.])\n",
      "deg_inv_sqrt is : \n",
      "tensor([0.7071, 0.5774, 0.7071])\n",
      "deg_inv_sqrt row is : \n",
      "tensor([0.7071, 0.5774, 0.5774, 0.7071, 0.7071, 0.5774, 0.7071])\n",
      "deg_inv_sqrt col is :\n",
      "tensor([0.5774, 0.7071, 0.7071, 0.5774, 0.7071, 0.5774, 0.7071])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "print(\"original edge_index \")\n",
    "print(edge_index)\n",
    "\n",
    "edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "print(\"new edge_index\")\n",
    "print(edge_index)\n",
    "\n",
    "row, col = edge_index\n",
    "print(\"row, col is :\")\n",
    "print(row, col)\n",
    "\n",
    "deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "print(\"deg is :\")\n",
    "print(deg)\n",
    "\n",
    "deg_inv_sqrt = deg.pow(-0.5)\n",
    "\n",
    "print(\"deg_inv_sqrt is : \")\n",
    "print(deg_inv_sqrt)\n",
    "\n",
    "print(\"deg_inv_sqrt row is : \")\n",
    "print(deg_inv_sqrt[row])\n",
    "\n",
    "print(\"deg_inv_sqrt col is :\")\n",
    "print(deg_inv_sqrt[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673ef4a",
   "metadata": {},
   "source": [
    "4. 规范化节点特征$\\phi$\n",
    "\n",
    "5. 聚合相邻节点特征(\"add\"聚合)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d33db9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;前面三步是`message passing`之前的预操作，第四、第五步可以采用`MessagePassing`类里面的方法完成。\n",
    "\n",
    "&emsp;&emsp;完整的代码如下所示:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05af5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        \n",
    "        # step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        print(\"edge_index:\")\n",
    "        print(edge_index)\n",
    "        \n",
    "        # step 2: Linearly transform node feature matrix\n",
    "        print('x_pre\\n', x)\n",
    "        x = self.lin(x)\n",
    "        print('x_aft\\n', x)\n",
    "        \n",
    "        # step3: Compute normalization\n",
    "        row, col = edge_index\n",
    "        print(\"row, col \\n\", row, col)\n",
    "        \n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        print('deg\\n', deg)\n",
    "        \n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        print('deg_inv_sqrt\\n', deg_inv_sqrt)\n",
    "        \n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        print('deg_inv_sqrt[row]', deg_inv_sqrt[row])\n",
    "        \n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        \n",
    "        # step5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "    \n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        \n",
    "        # Step 4: Normalize node features\n",
    "        print('x_j\\n', x_j)\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc60b34",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们建立的这个神经网络模型`GCNConv`继承于基础类`MessagePassing`，并且采用求和函数作为$\\square$函数，通过`super(GCNConv, self).__init__(aggr='add')`来初始化。在完成`1-3`步之后，调用`MessagePassing`中的`propagate()`方法来完成`4-5`步，进行信息传播。\n",
    "\n",
    "&emsp;&emsp;`message`函数用于对节点的邻居节点的信息进行标准化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2df46fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index:\n",
      "tensor([[0, 1, 1, 2, 0, 1, 2],\n",
      "        [1, 0, 2, 1, 0, 1, 2]])\n",
      "x_pre\n",
      " tensor([[0.0962, 0.8522],\n",
      "        [0.2487, 0.9627],\n",
      "        [0.8714, 0.4037]])\n",
      "x_aft\n",
      " tensor([[ 0.6273, -0.1826, -0.1128, -0.2466],\n",
      "        [ 0.5738, -0.1906, -0.0918, -0.4002],\n",
      "        [ 0.3286, -0.3220,  0.2442, -0.4737]], grad_fn=<AddmmBackward>)\n",
      "row, col \n",
      " tensor([0, 1, 1, 2, 0, 1, 2]) tensor([1, 0, 2, 1, 0, 1, 2])\n",
      "deg\n",
      " tensor([2., 3., 2.])\n",
      "deg_inv_sqrt\n",
      " tensor([0.7071, 0.5774, 0.7071])\n",
      "deg_inv_sqrt[row] tensor([0.7071, 0.5774, 0.5774, 0.7071, 0.7071, 0.5774, 0.7071])\n",
      "x_j\n",
      " tensor([[ 0.6273, -0.1826, -0.1128, -0.2466],\n",
      "        [ 0.5738, -0.1906, -0.0918, -0.4002],\n",
      "        [ 0.5738, -0.1906, -0.0918, -0.4002],\n",
      "        [ 0.3286, -0.3220,  0.2442, -0.4737],\n",
      "        [ 0.6273, -0.1826, -0.1128, -0.2466],\n",
      "        [ 0.5738, -0.1906, -0.0918, -0.4002],\n",
      "        [ 0.3286, -0.3220,  0.2442, -0.4737]], grad_fn=<IndexSelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/62/8d2vj9r962zftg9n42v8j4n40000gn/T/ipykernel_74453/2372978051.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.rand(3,2), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(torch.rand(3,2), dtype=torch.float)\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "conv = GCNConv(2, 4)\n",
    "out_put = conv(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8e1c0",
   "metadata": {},
   "source": [
    "<img src=\"../../images/12-graph_example_message_pass_1.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebffd1",
   "metadata": {},
   "source": [
    "## 实现边缘卷积\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffad539",
   "metadata": {},
   "source": [
    "&emsp;&emsp;边卷积层的数学定义如下：\n",
    "\n",
    "$$\n",
    "x_{i}^{(k)}=\\max _{j \\in N(i)} h_{\\Theta}\\left(x_{i}^{(k-1)}, x_{j}^{(k-1)}-x_{i}^{(k-1)}\\right)\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;其中$h_{\\Theta}$为多层感知机，类似于`GCN`，边卷积层同样继承于基类`MessagePassing`，不同在于采用`max`函数作为$\\square$函数。\n",
    "\n",
    "&emsp;&emsp;边卷积层的主要理论来自于论文[Dynamic Graph CNN for Learning on Point Clouds](https://arxiv.org/abs/1801.07829)这篇文章提出一种边卷积（`EdgeConv`）操作，来完成点云中点与点之间关系的建模，使得网络能够更好地学习局部和全局特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc3c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68af899",
   "metadata": {},
   "source": [
    "&emsp;&emsp;边缘卷积实际上是一种动态卷积，它使用特征空间中的最近邻重新计算每一层的图。幸运的是，`PyG`带有`GPU`加速的批处理`k-NN`图生成方法，名为`torch_geometric.nn.pool.knn_graph()`：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fd5df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "class DynamicEdgeConv(EdgeConv):\n",
    "    def __init__(self, in_channels, out_channels, k=6):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x, batch=None):\n",
    "        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n",
    "        return super().forward(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7329a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在这里，`knn_graph()`计算最近邻图，它进一步用于调用的`forward()`方法`EdgeConv`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddf477",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "https://blog.csdn.net/Jenny_oxaza/article/details/107561125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07362c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d695f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecole",
   "language": "python",
   "name": "ecole"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
