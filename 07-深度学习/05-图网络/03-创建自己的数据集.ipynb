{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83226df",
   "metadata": {},
   "source": [
    "## 创建自己的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247686cb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`PyTorch Geometric`提供了两个抽象类：\n",
    "\n",
    "1. `torch_geometric.data.Dataset`: \n",
    "\n",
    "2. `torch_geometric.data.InMemoryDataset`:\n",
    "\n",
    "&emsp;&emsp;前者适用于不能一次性放进内存中的大数据集，后者适用于可以全部放进内存中的小数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdfe8d",
   "metadata": {},
   "source": [
    "## In Memory Datasets数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eb339e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`torch_geometric.data.InMemoryDataset`有四个可选参数:\n",
    "\n",
    "1. `root(string, optional)`: 保存数据集的根目录。每个数据集都传递一个根文件夹，该跟文件夹指示数据集应该存储在何处。将根文件夹分成两个文件夹：未处理过的数据集被保存在`raw_dir`目录下；已处理过的数据集被保存在`processed_dir`目录下。\n",
    "\n",
    "2. `transform(callable, optional)`:\n",
    "\n",
    "3. `pre_transform(callable, optional)`:\n",
    "\n",
    "4. `pre_filter(callable, optional)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950228c8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;为了创建一个`torch_geometric.data.InMemoryDataset`，您需要实现四个基本方法：\n",
    "\n",
    "1. `torch_geometric.data.InMemoryDataset.raw_file_names()`：`raw_dir`需要找到其中的文件列表才能跳过下载。\n",
    "\n",
    "2. `torch_geometric.data.InMemoryDataset.processed_file_names()`:`processed_dir`需要找到的文件列表才能跳过处理。\n",
    "\n",
    "3. `torch_geometric.data.InMemoryDataset.download()`：将原始数据下载到`raw_dir`。\n",
    "\n",
    "4. `torch_geometric.data.InMemoryDataset.process()`：处理原始数据并将其保存到`processed_dir`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "279bc854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        download_url(url, self.raw_dir)\n",
    "        ...\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = [...]\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a25d3b",
   "metadata": {},
   "source": [
    "## 创建更大的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114049f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于无法全部放进内存中的大数据集，可以使用`torch_geometric.data.Dataset`。\n",
    "\n",
    "&emsp;&emsp;`torch_geometric.data.Dataset`的参数和`torch_geometric.data.InMemoryDataset`的一致。常用的方法如下：\n",
    "\n",
    "1. `len()`——获取数据集中的数据量。\n",
    "\n",
    "2. `get(idx)`——获取索引为`idx`的数据对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fcb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_1.pt', 'data_2.pt', ...]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        path = download_url(url, self.raw_dir)\n",
    "        ...\n",
    "\n",
    "    def process(self):\n",
    "        i = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            data = Data(...)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(i)))\n",
    "            i += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b47ab",
   "metadata": {},
   "source": [
    "## RecSys Challenge 2015构建自己的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb046958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hezhiqiang01/Desktop/anaconda/anaconda3/envs/ecole/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id                 timestamp    item_id category\n",
      "0           1  2014-04-07T10:51:09.277Z  214536502        0\n",
      "1           1  2014-04-07T10:54:09.868Z  214536500        0\n",
      "2           1  2014-04-07T10:54:46.998Z  214536506        0\n",
      "3           1  2014-04-07T10:57:00.306Z  214577561        0\n",
      "4           2  2014-04-07T13:56:37.614Z  214662742        0\n",
      "   session_id                 timestamp    item_id  price  quantity\n",
      "0      420374  2014-04-06T18:44:58.314Z  214537888  12462         1\n",
      "1      420374  2014-04-06T18:44:58.325Z  214537850  10471         1\n",
      "2      281626  2014-04-06T09:40:13.032Z  214535653   1883         1\n",
      "3      420368  2014-04-04T06:13:28.848Z  214530572   6073         1\n",
      "4      420368  2014-04-04T06:13:28.858Z  214835025   2617         1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/yoochoose-data/yoochoose-clicks.dat', header=None)\n",
    "df.columns=['session_id','timestamp','item_id','category']\n",
    "print(df.head())\n",
    "\n",
    "buy_df = pd.read_csv('../../data/yoochoose-data/yoochoose-buys.dat', header=None)\n",
    "buy_df.columns=['session_id','timestamp','item_id','price','quantity']\n",
    "print(buy_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dea02d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:51:09.277Z</td>\n",
       "      <td>2053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:09.868Z</td>\n",
       "      <td>2052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:54:46.998Z</td>\n",
       "      <td>2054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07T10:57:00.306Z</td>\n",
       "      <td>9876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-07T13:56:37.614Z</td>\n",
       "      <td>19448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                 timestamp  item_id category\n",
       "0           1  2014-04-07T10:51:09.277Z     2053        0\n",
       "1           1  2014-04-07T10:54:09.868Z     2052        0\n",
       "2           1  2014-04-07T10:54:46.998Z     2054        0\n",
       "3           1  2014-04-07T10:57:00.306Z     9876        0\n",
       "4           2  2014-04-07T13:56:37.614Z    19448        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_encoder = LabelEncoder()\n",
    "df['item_id'] = item_encoder.fit_transform(df.item_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569c099",
   "metadata": {},
   "source": [
    "### 创建Dataset\n",
    "\n",
    "这里我们将预处理过的数据创建成为`Dataset`对象。对于每个`session`，里面的每个商品（`item`）看作一个节点，因此每个`session`里所有的商品组成一个图。\n",
    "\n",
    "首先，我们将数据集按照`session_id`进行分组，分组过程中`item_id`也要被重新编码，因为对于每个图，每个节点的`index`应该从`0`开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33be2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "class YooChooseBinaryDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(YooChooseBinaryDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['../../data/yoochoose_click_binary_1M_sess.dataset']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "\n",
    "        # process by session_id\n",
    "        grouped = df.groupby('session_id')\n",
    "        for session_id, group in tqdm(grouped):\n",
    "            sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
    "            group = group.reset_index(drop=True)\n",
    "            group['sess_item_id'] = sess_item_id\n",
    "            node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
    "\n",
    "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "            target_nodes = group.sess_item_id.values[1:]\n",
    "            source_nodes = group.sess_item_id.values[:-1]\n",
    "\n",
    "            edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "            x = node_features\n",
    "\n",
    "            y = torch.FloatTensor([group.label.values[0]])\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d150ef7",
   "metadata": {},
   "source": [
    "然后我们对数据集进行随机排序，分成`training`, `validation`和`testing`三个子数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99b53e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/62/8d2vj9r962zftg9n42v8j4n40000gn/T/ipykernel_77647/4000438129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m800000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m800000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m900000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m900000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:800000]\n",
    "val_dataset = dataset[800000:900000]\n",
    "test_dataset = dataset[900000:]\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df057a8b",
   "metadata": {},
   "source": [
    "https://www.pytorchtutorial.com/pytorch-geometric-for-gnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab61f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecole",
   "language": "python",
   "name": "ecole"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
