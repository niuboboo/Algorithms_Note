{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8a3b93",
   "metadata": {},
   "source": [
    "## GoogLeNet实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de194c4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`GoogleNet`里面最重要的就是`Inception`块，也就是不做选择，全都要。\n",
    "\n",
    "&emsp;&emsp;`Inception`块从`4`个路径上，不同层面抽取信息，然后在输出通道维结合。\n",
    "\n",
    "1. 输入直接经过一个$1 \\times 1$的卷积层，得到输出;\n",
    "2. 输入先经过一个$1 \\times 1$的卷积层，然后再经过一个$3 \\times 3$的卷积层，`pad=1`;\n",
    "3. 输入先经过一个$1 \\times 1$的卷积层，然后再经过一个$5 \\times 5$的卷积层，`pad=2`;\n",
    "4. 输入先经过一个$3 \\times 3$的`MaxPooling`, `pad=1`, 然后再经过一个$1 \\times 1$的卷积层;\n",
    "\n",
    "&emsp;&emsp;上述四个操作的高宽都是等同的，但是在通道数层面时候累加的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86330cc5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`Inception`有各种后续版本:\n",
    "\n",
    "1. `Inception-BN`(v2)使用`batch normalization`(后面介绍);\n",
    "2. `Inception-V3`修改了`Inception`块;\n",
    "\n",
    "- 替换$5 \\times 5$为多个$3 \\times 3$卷积层;\n",
    "- 替换$5 \\times 5$为$1 \\times 7$和$7 \\times 1$卷积层;\n",
    "- 替换$3 \\times 3$为$1 \\times 3$和$3 \\times 1$卷积层;\n",
    "- 更深\n",
    "\n",
    "3. `Inception-V4`使用残差连接;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6288a442",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`Inception`块用`4`条有不同超参数的卷积层和池化层来抽取不同的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c9112c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e23ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = F.relu(self.p1_1(x))\n",
    "        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n",
    "        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n",
    "        p4 = F.relu(self.p4_2(self.p4_1(x)))\n",
    "        # 在通道维度上连结输出\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2d5ec",
   "metadata": {},
   "source": [
    "&emsp;&emsp;之后逐一实现GoogLeNet的每个模块:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230a5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a7af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82ae94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a332c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fa81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   nn.Flatten())\n",
    "\n",
    "net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295f36fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
      "Sequential output shape:\t torch.Size([1, 192, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 480, 6, 6])\n",
      "Sequential output shape:\t torch.Size([1, 832, 3, 3])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 96, 96))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05d2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"Use 4 processes to read the data.\"\"\"\n",
    "    return 4\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    \n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "        \n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\", train=False, transform=trans, download=True)\n",
    "    \n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118e48ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tinyzqh/miniforge3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-wdh4qigd/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=128, resize=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd75c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db07bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\n",
    "reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
    "astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = argmax(y_hat, axis=1)\n",
    "    cmp = astype(y_hat, y.dtype) == y\n",
    "    return float(reduce_sum(astype(cmp, y.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1bab159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "        if not device: # 如果没有指定device, 就用网络参数中的所给定的那个device。\n",
    "            device = next(iter(net.parameters())).device\n",
    "    \n",
    "    metric = Accumulator(2)\n",
    "    \n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X, list):\n",
    "            X = [x.to(device) for x in X]  # 将数据挪到device上。\n",
    "        else:\n",
    "            X = X.to(device)\n",
    "            \n",
    "        y = y.to(device)\n",
    "        \n",
    "        metric.add(accuracy(net(X), y), y.numel())\n",
    "        \n",
    "        return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f440046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    \n",
    "    net.apply(init_weights)  # 对net里面的每一个parameter都去run一下init_weights这个函数。\n",
    "    print(\"trainng on {}\".format(device))\n",
    "    \n",
    "    net.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    num_batches = len(train_iter)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            y_hat = net(X)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
    "            \n",
    "            train_loss = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            \n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                print(\"epoch {}, train_loss {}, train_acc {}\".format(epoch + (i + 1) / num_batches, \n",
    "                                                                  train_loss, train_acc))\n",
    "    test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "    print(f'loss {train_loss:.3f}, train acc {train_acc:.3f}, 'f'test acc {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b0f204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca7074e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainng on cpu\n",
      "epoch 0.19829424307036247, train_loss 2.302106060007567, train_acc 0.10332661290322581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tinyzqh/miniforge3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/tinyzqh/miniforge3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/tinyzqh/miniforge3/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/tinyzqh/miniforge3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/tinyzqh/miniforge3/lib/python3.9/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/tinyzqh/miniforge3/lib/python3.9/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/tinyzqh/miniforge3/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/tinyzqh/miniforge3/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x9/xgj8n5xd2bb0cv55w7c72bn40000gn/T/ipykernel_33800/1913885567.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/x9/xgj8n5xd2bb0cv55w7c72bn40000gn/T/ipykernel_33800/2139600443.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.1, 10\n",
    "train(net, train_iter, test_iter, num_epochs, lr, try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03342f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
