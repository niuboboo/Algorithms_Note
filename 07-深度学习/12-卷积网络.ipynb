{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ecd6cd",
   "metadata": {},
   "source": [
    "## 重新考察全连接层\n",
    "\n",
    "&emsp;&emsp;将输入和输出变形为矩阵(宽度，高度)。对应的，我们可以将权重变形为$4-D$的张量, 从$(h, w)$到$(h^{\\prime}, w^{\\prime})$。\n",
    "\n",
    "&emsp;&emsp;那么我们的输出可以表示为$h_{i, j}$:\n",
    "\n",
    "$$\n",
    "h_{i, j}=\\sum_{k l} w_{i, j, k, l} x_{k, l}=\\sum_{a b} v_{i, j, a, b} x_{i+a, j+b}\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;其中$x_{k, l}$是我们的输入, 然后对$k, l$求和。之后对下标做一些变换: $v_{i,j,a,b} = w_{i, j, i+a, j+b}$, 来引出卷积的做法, 其中$v$是$w$的重新索引:。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a57ec",
   "metadata": {},
   "source": [
    "### 平移不变性\n",
    "\n",
    "&emsp;&emsp;假设$x$的位置的变换，这将导致权重$v$值的变换。因此想要实现平移不变性，$v$不应该依赖于$(i, j)$，解决方法是$v_{i,j,a,b}=v_{a, b}$:\n",
    "\n",
    "$$\n",
    "h_{i,j} = \\sum_{a,b} v_{a,b} x_{i+a, j+b}\n",
    "$$\n",
    "\n",
    "&emsp;&emsp;这就是2维卷积。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e593e9f",
   "metadata": {},
   "source": [
    "### 局部性\n",
    "\n",
    "&emsp;&emsp;当评估$h_{i,j}$时，我们不应该用远离$x_{i,j}$的参数。解决方案是：当$|a|, |b| > \\Delta$时，使得$v_{a, b}=0$:\n",
    "\n",
    "$$\n",
    "h_{i, j}=\\sum_{a=-\\Delta}^{\\Delta} \\sum_{b=-\\Delta}^{\\Delta} v_{a, b} x_{i+a, j+b}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b36dab",
   "metadata": {},
   "source": [
    "## 卷积层\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ccbd1c",
   "metadata": {},
   "source": [
    "<img src=\"../images/07-juanji.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e5fbc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;上图中$19$的计算方式如下: $0 \\times 0 + 1 \\times 1 + 3 \\times 2 + 4 \\times 3 = 19$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f03bb0",
   "metadata": {},
   "source": [
    "&emsp;&emsp;假设我们的\n",
    "\n",
    "1. 输入为$X$, 它的维度为$n_{h} \\times n_{w}$；\n",
    "2. 核为$W$, 它的纬度为$k_{h} \\times k_{w}$,；\n",
    "3. 偏差$b \\in \\mathbf{R}$。\n",
    "4. 输出为$Y$, 纬度为: $(n_{h} - k_{h} + 1) \\times (n_{w} - k_{w} + 1)$。\n",
    "\n",
    "&emsp;&emsp;其中的$W$和$b$是可学习参数。\n",
    "\n",
    "&emsp;&emsp;卷积层是将输入和核矩阵进行交叉相关计算，再加上偏移后得到输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f06f15",
   "metadata": {},
   "source": [
    "### 互相关运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879e50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def corr2d(Image, Kernel):\n",
    "    N_h, N_w = Image.shape  # 获取到图像的高和宽。\n",
    "    K_h, K_w = Kernel.shape  # 获取到核的高和宽。\n",
    "    Y = torch.zeros((N_h - K_h + 1, N_w - K_w + 1))  # 输出结果的维度。这里步长是为1的。\n",
    "    for row in range(Y.shape[0]):\n",
    "        for col in range(Y.shape[1]):\n",
    "            Y[row, col] = (Image[row : row + K_h, col : col + K_w] * Kernel).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405ddf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19., 25.],\n",
      "        [37., 43.]])\n"
     ]
    }
   ],
   "source": [
    "Image = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "Kernel = torch.tensor([[0, 1], [2, 3]])\n",
    "print(corr2d(Image, Kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96d471",
   "metadata": {},
   "source": [
    "### 二维卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cbc1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50294d74",
   "metadata": {},
   "source": [
    "&emsp;&emsp;基于上述所实现的二维卷机，我们来实现一个简单的应用。检测图像中不同颜色的边缘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d3d7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(6, 8)\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba9a884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kernel = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f6618",
   "metadata": {},
   "source": [
    "&emsp;&emsp;基于$[1.0, -1.0]$的这样一个`kernel`，输出`Y`中的`1`代表从白色到黑色的边缘，`-1`表示从黑色到白色的边缘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0518687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, Kernel)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec07aac",
   "metadata": {},
   "source": [
    "### 学习由X生成Y的卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e85db71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0, loss 10.075425148010254\n",
      "batch 2, loss 2.4747474193573\n",
      "batch 4, loss 0.7364716529846191\n",
      "batch 6, loss 0.25515487790107727\n",
      "batch 8, loss 0.0967092365026474\n"
     ]
    }
   ],
   "source": [
    "# 第一个参数1表示输入的通道，第二个参数表述输出通道数也是1。\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size = (1, 2), bias = False)\n",
    "\n",
    "X = X.reshape((1, 1, 6, 8))  # 需要增加两个维度，一个是通道位，一个是批量大小位。\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    loss = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    loss.sum().backward()\n",
    "    conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad\n",
    "    \n",
    "    if (i + 2) % 2 == 0:\n",
    "        print(\"batch {}, loss {}\".format(i, loss.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d19c5",
   "metadata": {},
   "source": [
    "&emsp;&emsp;查看一下学习结果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ddffb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.9663, -1.0163]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25152f2b",
   "metadata": {},
   "source": [
    "## 填充和步幅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072af033",
   "metadata": {},
   "source": [
    "&emsp;&emsp;填充和步幅是控制卷积层输出大小的两个参数。输出图片的大小为$(n_{h} - k_{h} + 1) \\times (n_{w} - k_{w} + 1)$, 因此卷积之后输出图片会越变越小，而深度学习考虑的是如何用更深的网络来训练模型，所以想要更深的网络的话，我们需要做填充：**在输入周围添加额外的行和列**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017e804",
   "metadata": {},
   "source": [
    "&emsp;&emsp;假设填充的为$p_{h}$行和$p_{w}$列，那么此时输出图片的大小为：$(n_{h} - k_{h} + p_{h} + 1) \\times (n_{w} - k_{w} + p_{w} + 1)$。\n",
    "\n",
    "&emsp;&emsp;通常来说取，$p_{h}=k_{h} - 1$, $p_{w} = k_{w} - 1$，此时的输入输出维度是相等的：\n",
    "\n",
    "- 当$k_{h}$为奇数：在上下两侧填充$p_{h} / 2$。\n",
    "- 当$k_{h}$为偶数：在上侧填充$「p_{h} / 2$，下侧填充$p_{h} / 2」$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562803c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;对于填充来说，是希望可以控制图片不要变小地太快，但是对于一张很大的图片来说，我们希望它能够快速变小的话，就可以通过步幅来进行调整。不然的话，网络可能会太深，需要大量的计算得出较小的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a6a82",
   "metadata": {},
   "source": [
    "&emsp;&emsp;给定高度$s_{h}$和宽度$s_{w}$的步幅，输出形状是：$((n_{h} - k_{h} + p_{h}) / s_{h} + 1) \\times ((n_{w} - k_{w} + p_{w}) / s_{w} + 1)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3469c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def comp_conv2d(conv2d, x):\n",
    "    x = x.reshape((1, 1) + x.shape)  # 添加批量数和通道数。\n",
    "    y = conv2d(x)  # 应用卷积。\n",
    "    return y.reshape(y.shape[2:])  # 去除掉批量数和通道数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27eebe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)  # 输入输出通道数都为1。padding=1的话，会在上下左右各填充一行。\n",
    "x = torch.rand(size=(8, 8))  \n",
    "comp_conv2d(conv2d, x).shape  # 输出大小和输入大小是一样的了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb0333d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当核的大小变为(5, 3)的时候，只有当上下填充2行，左右填充1列的时候，输出大小才会一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a55c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df3a8d",
   "metadata": {},
   "source": [
    "&emsp;&emsp;将高度和宽度的步幅设置为2的时候:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dcbf309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f0090",
   "metadata": {},
   "source": [
    "&emsp;&emsp;一个稍微复杂一点的例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b51699b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f405d3",
   "metadata": {},
   "source": [
    "## 问答\n",
    "\n",
    "1. 核大小、填充、步幅这几个超参数的重要程度排序是怎样的？\n",
    "\n",
    "- 一般来说填充就是取核的大小减去1，使得输入输出的大小一样。\n",
    "- 步幅通常选择为1，通常计算量很大的话，我们不会选择步幅为1的情况。\n",
    "\n",
    "2. 卷积核的边长为什么一般取奇数？\n",
    "\n",
    "- 卷积核的边长取奇数的原因在于填充的时候能够使得上下填充是对称的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabeb72",
   "metadata": {},
   "source": [
    "## 卷积层里的多输入多输出通道"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f3658b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;通道数通常是大家通常会仔细去设计的超参数:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f310e3",
   "metadata": {},
   "source": [
    "- **多个输入通道**:\n",
    "\n",
    "&emsp;&emsp;图像通常是多个输入通道的，假设我们的\n",
    "\n",
    "1. 输入为$X$, 它的维度为: $c_{i} \\times n_{h} \\times n_{w}$；\n",
    "2. 核为$W$, 它的纬度为: $c_{i} \\times k_{h} \\times k_{w}$；\n",
    "3. 偏差$b \\in \\mathbf{R}$。\n",
    "4. 输出为$Y$, 纬度为: $m_{h} \\times m_{w}$。\n",
    "\n",
    "&emsp;&emsp;也就是说，输出是一个单通道的。每一个通道的对应元素相加，得到最终的单通道的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8047bd",
   "metadata": {},
   "source": [
    "- **多个输出通道**:\n",
    "\n",
    "&emsp;&emsp;我们可以用多个三维卷积核，每个核生成一个输出通道。\n",
    "\n",
    "1. 输入为$X$, 它的维度为: $c_{i} \\times n_{h} \\times n_{w}$；\n",
    "2. 核为$W$, 它的纬度为: $c_{o} \\times c_{i} \\times k_{h} \\times k_{w}$；\n",
    "3. 偏差$b \\in \\mathbf{R}$。\n",
    "4. 输出为$Y$, 纬度为: $c_{o} \\times m_{h} \\times m_{w}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea69f61",
   "metadata": {},
   "source": [
    "- **多个输入和输出通道**\n",
    "\n",
    "&emsp;&emsp;每个输出通道可以识别特定模式。输入通道核识别并组合输入中的模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b0c0a",
   "metadata": {},
   "source": [
    "- $1 \\times 1$卷积层\n",
    "\n",
    "&emsp;&emsp;$k_{h} = k_{w} = 1$是一个受欢迎的选择，它不识别空间模式，只是融合通道。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01844b",
   "metadata": {},
   "source": [
    "- **二维卷积层通用情况**:\n",
    "\n",
    "&emsp;&emsp;我们可以用多个三维卷积核，每个核生成一个输出通道。\n",
    "\n",
    "1. 输入为$X$, 它的维度为: $c_{i} \\times n_{h} \\times n_{w}$；\n",
    "2. 核为$W$, 它的纬度为: $c_{o} \\times c_{i} \\times k_{h} \\times k_{w}$；\n",
    "3. 偏差$c_{o} \\times c_{i}$。\n",
    "4. 输出为$Y$, 纬度为: $c_{o} \\times m_{h} \\times m_{w}$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3cbdb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def corr2d(Image, Kernel):\n",
    "    N_h, N_w = Image.shape  # 获取到图像的高和宽。\n",
    "    K_h, K_w = Kernel.shape  # 获取到核的高和宽。\n",
    "    Y = torch.zeros((N_h - K_h + 1, N_w - K_w + 1))  # 输出结果的维度。这里步长是为1的。\n",
    "    for row in range(Y.shape[0]):\n",
    "        for col in range(Y.shape[1]):\n",
    "            Y[row, col] = (Image[row : row + K_h, col : col + K_w] * Kernel).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ea3e3",
   "metadata": {},
   "source": [
    "- **实现多输入通道的互相关计算**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "991992d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3938cb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;验证互相关运算的输出:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f73ae2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92b266",
   "metadata": {},
   "source": [
    "- **计算多个通道的输出的互相关函数**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fd027f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)  # 在0这个维度上进行stack。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38d276e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K+1, K+2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89c686a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74586b",
   "metadata": {},
   "source": [
    "## $1 \\times 1$卷积等价于全连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "626b875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfe35978",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, ((3, 3, 3)))\n",
    "K = torch.normal(0, 1, ((2, 3, 1, 1)))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030700e3",
   "metadata": {},
   "source": [
    "## 问题\n",
    "\n",
    "- 输入和输出的通道数如果不变的话，通道数一般也不变；输入和输出的通道数减半的时候，输出的通道数通常会加一倍，也就是空间信息压缩了，把提取的信息在更多的通道里面存储下来。\n",
    "\n",
    "1. **网络越深，padding 0越多，是否会影响性能？**\n",
    "\n",
    "&emsp;&emsp;计算性能增加了一点点，对于模型性能是不会影响的，因为0对于卷积是没有多少影响的。\n",
    "\n",
    "2. **每个通道的卷积核都不一样吗？同一层不同通道的卷积核大小必须一样吗？**\n",
    "\n",
    "&emsp;&emsp;每个通道的卷积核是不一样的，同一层不同通道的卷积核大小必须一样。\n",
    "\n",
    "3. **计算卷积时，bias的有无，对结果影响大吗？bias的作用怎么理解？**\n",
    "\n",
    "&emsp;&emsp;bias是有一些作用的，但是它的作用会变得越来越低。比如像数据的均值不为0的时候，bias就可以去等价于均值的负数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fe2dc",
   "metadata": {},
   "source": [
    "## 池化层\n",
    "\n",
    "&emsp;&emsp;卷积层对于位置信息是非常敏感的，而实际的图像因为照明，物体的位置，比例，外观等因图像而异，所以我们需要一定的平移不变性。\n",
    "\n",
    "### 二维最大池化\n",
    "\n",
    "&emsp;&emsp;每次返回二维窗口中的最大值。因此最大池化层会允许输入的元素发生小小的偏移，并且会有一定的模糊效果，但是它没有可学习的参数，输出通道数会等于输入通道数。\n",
    "\n",
    "### 平均池化层\n",
    "\n",
    "&emsp;&emsp;把最大的那个操作子变成平均。最大池化层获取的是每个窗口中最强的那个信号，平均池化层的信号强化会弱很多，但是会有一个比较柔和化的效果。\n",
    "\n",
    "### 小结\n",
    "\n",
    "&emsp;&emsp;它会缓解卷积层带来的位置敏感性。同样有窗口大小、填充、和步幅作为超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41ec18",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29df2f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;实现池化层的正向传播:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4344a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def pool2d(X, pool_size, mode=\"max\"):\n",
    "    x_h, x_w = X.shape\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((x_h - p_h + 1, x_w - p_w + 1))  # 创建输出\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == \"max\":\n",
    "                Y[i, j] = X[i:i+p_h, j:j+p_w].max()\n",
    "            elif mode == \"avg\":\n",
    "                Y[i, j] = X[i:i+p_h, j:j+p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1560620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "704f7e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证最大池化\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afe5ed61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证平均池化\n",
    "pool2d(X, (2, 2), mode=\"avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e72e79",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`torch`中的代码实现:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e721061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape(1, 1, 4, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a5caf",
   "metadata": {},
   "source": [
    "&emsp;&emsp;深度学习中的步幅与池化窗口相同(torch框架是这样的)，也就是移动的时候，下一个池化区域与上一个池化区域没有重叠部分:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "315e0aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)  # 设定一个3 X 3的窗口\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1935d65b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;填充和步幅可以手动设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19931787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d6f91",
   "metadata": {},
   "source": [
    "&emsp;&emsp;设定一个任意大小的矩形池化窗口，并分别设定填充和步幅的高度和宽度:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b006b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  3.],\n",
       "          [ 9., 11.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), padding=(1, 1), stride=(2, 3))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae3c63",
   "metadata": {},
   "source": [
    "&emsp;&emsp;池化层在每个通道上单独运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92bd96f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X+1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "876c14d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376ea40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddd05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
