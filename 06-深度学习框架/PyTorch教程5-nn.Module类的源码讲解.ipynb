{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec84adc8",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1285a9",
   "metadata": {},
   "source": [
    "- [https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b77b2",
   "metadata": {},
   "source": [
    "nn.Module是所有神经网络的Base Class，我们自己编写的模型应该继承自这个基础类。Modules应该包含其它的Modules。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a8956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd5427",
   "metadata": {},
   "source": [
    "## 源码解析\n",
    "\n",
    "- [https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ca341",
   "metadata": {},
   "source": [
    "### init方法\n",
    "\n",
    "主要的类是`class Module:`类，其init方法的源码如下：\n",
    "\n",
    "```python\n",
    "def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
    "        \"\"\"\n",
    "        torch._C._log_api_usage_once(\"python.nn_module\")\n",
    "\n",
    "        self.training = True\n",
    "        self._parameters: Dict[str, Optional[Parameter]] = OrderedDict()\n",
    "        self._buffers: Dict[str, Optional[Tensor]] = OrderedDict()\n",
    "        self._non_persistent_buffers_set: Set[str] = set()\n",
    "        self._backward_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._is_full_backward_hook = None\n",
    "        self._forward_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._forward_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._state_dict_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._load_state_dict_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._modules: Dict[str, Optional['Module']] = OrderedDict()\n",
    "```\n",
    "\n",
    "可以看到里面有很多成员变量，大部分是字典的形式。默认情况下training=True，也就是batchnorm，dropout都是遵循training=True这种设定的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be849f",
   "metadata": {},
   "source": [
    "### register_buffer\n",
    "\n",
    "register_buffer方法的函数源码如下，是将buffer注册到module中去。参数有name，tensor和persistent。\n",
    "\n",
    "```python\n",
    "def register_buffer(self, name: str, tensor: Optional[Tensor], persistent: bool = True) -> None:\n",
    "        r\"\"\"Adds a buffer to the module.\n",
    "        This is typically used to register a buffer that should not to be\n",
    "        considered a model parameter. For example, BatchNorm's ``running_mean``\n",
    "        is not a parameter, but is part of the module's state. Buffers, by\n",
    "        default, are persistent and will be saved alongside parameters. This\n",
    "        behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
    "        only difference between a persistent buffer and a non-persistent buffer\n",
    "        is that the latter will not be a part of this module's\n",
    "        :attr:`state_dict`.\n",
    "        Buffers can be accessed as attributes using given names.\n",
    "        Args:\n",
    "            name (string): name of the buffer. The buffer can be accessed\n",
    "                from this module using the given name\n",
    "            tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
    "                that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
    "                the buffer is **not** included in the module's :attr:`state_dict`.\n",
    "            persistent (bool): whether the buffer is part of this module's\n",
    "                :attr:`state_dict`.\n",
    "        Example::\n",
    "            >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        \"\"\"\n",
    "        if persistent is False and isinstance(self, torch.jit.ScriptModule):\n",
    "            raise RuntimeError(\"ScriptModule does not support non-persistent buffers\")\n",
    "\n",
    "        if '_buffers' not in self.__dict__:\n",
    "            raise AttributeError(\n",
    "                \"cannot assign buffer before Module.__init__() call\")\n",
    "        elif not isinstance(name, torch._six.string_classes):\n",
    "            raise TypeError(\"buffer name should be a string. \"\n",
    "                            \"Got {}\".format(torch.typename(name)))\n",
    "        elif '.' in name:\n",
    "            raise KeyError(\"buffer name can't contain \\\".\\\"\")\n",
    "        elif name == '':\n",
    "            raise KeyError(\"buffer name can't be empty string \\\"\\\"\")\n",
    "        elif hasattr(self, name) and name not in self._buffers:\n",
    "            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
    "        elif tensor is not None and not isinstance(tensor, torch.Tensor):\n",
    "            raise TypeError(\"cannot assign '{}' object to buffer '{}' \"\n",
    "                            \"(torch Tensor or None required)\"\n",
    "                            .format(torch.typename(tensor), name))\n",
    "        else:\n",
    "            self._buffers[name] = tensor\n",
    "            if persistent:\n",
    "                self._non_persistent_buffers_set.discard(name)\n",
    "            else:\n",
    "                self._non_persistent_buffers_set.add(name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64519e49",
   "metadata": {},
   "source": [
    "### register_parameter\n",
    "\n",
    "register_parameter是一个比register_buffer更加常用的一个方法。参数有name，和param两个。其源代码如下所示：\n",
    "\n",
    "```python\n",
    "def register_parameter(self, name: str, param: Optional[Parameter]) -> None:\n",
    "        r\"\"\"Adds a parameter to the module.\n",
    "        The parameter can be accessed as an attribute using given name.\n",
    "        Args:\n",
    "            name (string): name of the parameter. The parameter can be accessed\n",
    "                from this module using the given name\n",
    "            param (Parameter or None): parameter to be added to the module. If\n",
    "                ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
    "                are ignored. If ``None``, the parameter is **not** included in the\n",
    "                module's :attr:`state_dict`.\n",
    "        \"\"\"\n",
    "        if '_parameters' not in self.__dict__:\n",
    "            raise AttributeError(\n",
    "                \"cannot assign parameter before Module.__init__() call\")\n",
    "\n",
    "        elif not isinstance(name, torch._six.string_classes):\n",
    "            raise TypeError(\"parameter name should be a string. \"\n",
    "                            \"Got {}\".format(torch.typename(name)))\n",
    "        elif '.' in name:\n",
    "            raise KeyError(\"parameter name can't contain \\\".\\\"\")\n",
    "        elif name == '':\n",
    "            raise KeyError(\"parameter name can't be empty string \\\"\\\"\")\n",
    "        elif hasattr(self, name) and name not in self._parameters:\n",
    "            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
    "\n",
    "        if param is None:\n",
    "            self._parameters[name] = None\n",
    "        elif not isinstance(param, Parameter):\n",
    "            raise TypeError(\"cannot assign '{}' object to parameter '{}' \"\n",
    "                            \"(torch.nn.Parameter or None required)\"\n",
    "                            .format(torch.typename(param), name))\n",
    "        elif param.grad_fn:\n",
    "            raise ValueError(\n",
    "                \"Cannot assign non-leaf Tensor to parameter '{0}'. Model \"\n",
    "                \"parameters must be created explicitly. To express '{0}' \"\n",
    "                \"as a function of another Tensor, compute the value in \"\n",
    "                \"the forward() method.\".format(name))\n",
    "        else:\n",
    "            self._parameters[name] = param  # 将参数添加到_parameters这个字典中，键是name，值是param。\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a232816b",
   "metadata": {},
   "source": [
    "我们可以使用register_parameter来自定义一个模型。比如说通过这个模型计算一个高斯分布的负log概率。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9fef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mean', tensor([0.]))])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GaussianModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GaussianModel, self).__init__()\n",
    "        self.register_parameter('mean', nn.Parameter(torch.zeros(1), requires_grad=True))\n",
    "        self.pdf = torch.distributions.Normal(self.state_dict()['mean'], torch.tensor([1.0]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return -self.pdf.log_prob(x)\n",
    "model = GaussianModel()\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26169f6",
   "metadata": {},
   "source": [
    "### add_module方法\n",
    "\n",
    "函数原型为：\n",
    "\n",
    "```python\n",
    "add_module(name, module)\n",
    "```\n",
    "\n",
    "通过`add_module`方法，我们可以将子`module`添加到当前的`module`中去。\n",
    "\n",
    "函数源码为：\n",
    "\n",
    "```python\n",
    "def add_module(self, name: str, module: Optional['Module']) -> None:\n",
    "        r\"\"\"Adds a child module to the current module.\n",
    "        The module can be accessed as an attribute using the given name.\n",
    "        Args:\n",
    "            name (string): name of the child module. The child module can be\n",
    "                accessed from this module using the given name\n",
    "            module (Module): child module to be added to the module.\n",
    "        \"\"\"\n",
    "        if not isinstance(module, Module) and module is not None:\n",
    "            raise TypeError(\"{} is not a Module subclass\".format(\n",
    "                torch.typename(module)))\n",
    "        elif not isinstance(name, torch._six.string_classes):\n",
    "            raise TypeError(\"module name should be a string. Got {}\".format(\n",
    "                torch.typename(name)))\n",
    "        elif hasattr(self, name) and name not in self._modules:\n",
    "            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
    "        elif '.' in name:\n",
    "            raise KeyError(\"module name can't contain \\\".\\\", got: {}\".format(name))\n",
    "        elif name == '':\n",
    "            raise KeyError(\"module name can't be empty string \\\"\\\"\")\n",
    "        self._modules[name] = module\n",
    "```\n",
    "\n",
    "可以看到就是非常简单的将name和module作为键值对放入到模型中去。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aefc56",
   "metadata": {},
   "source": [
    "### children\n",
    "\n",
    "返回可以迭代的子模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93313c",
   "metadata": {},
   "source": [
    "### apply_方法\n",
    "\n",
    "apply是以一个函数作为一个参数，可以将函数递归地作用到子模块中去。这些子模块是能够通过.children()返回得到的子模块。通常用来初始化模型的参数。\n",
    "\n",
    "```python\n",
    "def _apply(self, fn):\n",
    "        for module in self.children():\n",
    "            module._apply(fn)\n",
    "\n",
    "        def compute_should_use_set_data(tensor, tensor_applied):\n",
    "            if torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n",
    "                # If the new tensor has compatible tensor type as the existing tensor,\n",
    "                # the current behavior is to change the tensor in-place using `.data =`,\n",
    "                # and the future behavior is to overwrite the existing tensor. However,\n",
    "                # changing the current behavior is a BC-breaking change, and we want it\n",
    "                # to happen in future releases. So for now we introduce the\n",
    "                # `torch.__future__.get_overwrite_module_params_on_conversion()`\n",
    "                # global flag to let the user control whether they want the future\n",
    "                # behavior of overwriting the existing tensor or not.\n",
    "                return not torch.__future__.get_overwrite_module_params_on_conversion()\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        for key, param in self._parameters.items():\n",
    "            if param is None:\n",
    "                continue\n",
    "            # Tensors stored in modules are graph leaves, and we don't want to\n",
    "            # track autograd history of `param_applied`, so we have to use\n",
    "            # `with torch.no_grad():`\n",
    "            with torch.no_grad():\n",
    "                param_applied = fn(param)\n",
    "            should_use_set_data = compute_should_use_set_data(param, param_applied)\n",
    "            if should_use_set_data:\n",
    "                param.data = param_applied\n",
    "                out_param = param\n",
    "            else:\n",
    "                assert isinstance(param, Parameter)\n",
    "                assert param.is_leaf\n",
    "                out_param = Parameter(param_applied, param.requires_grad)\n",
    "                self._parameters[key] = out_param\n",
    "\n",
    "            if param.grad is not None:\n",
    "                with torch.no_grad():\n",
    "                    grad_applied = fn(param.grad)\n",
    "                should_use_set_data = compute_should_use_set_data(param.grad, grad_applied)\n",
    "                if should_use_set_data:\n",
    "                    out_param.grad.data = grad_applied\n",
    "                else:\n",
    "                    assert param.grad.is_leaf\n",
    "                    out_param.grad = grad_applied.requires_grad_(param.grad.requires_grad)\n",
    "\n",
    "        for key, buf in self._buffers.items():\n",
    "            if buf is not None:\n",
    "                self._buffers[key] = fn(buf)\n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "主要是对，module，param和buffer这三个部分用apply函数f。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3747e5",
   "metadata": {},
   "source": [
    "### apply_方法\n",
    "\n",
    "```python\n",
    "def apply(self: T, fn: Callable[['Module'], None]) -> T:\n",
    "        r\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
    "        as well as self. Typical use includes initializing the parameters of a model\n",
    "        (see also :ref:`nn-init-doc`).\n",
    "        Args:\n",
    "            fn (:class:`Module` -> None): function to be applied to each submodule\n",
    "        Returns:\n",
    "            Module: self\n",
    "        Example::\n",
    "            >>> @torch.no_grad()\n",
    "            >>> def init_weights(m):\n",
    "            >>>     print(m)\n",
    "            >>>     if type(m) == nn.Linear:\n",
    "            >>>         m.weight.fill_(1.0)\n",
    "            >>>         print(m.weight)\n",
    "            >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
    "            >>> net.apply(init_weights)\n",
    "            Linear(in_features=2, out_features=2, bias=True)\n",
    "            Parameter containing:\n",
    "            tensor([[ 1.,  1.],\n",
    "                    [ 1.,  1.]])\n",
    "            Linear(in_features=2, out_features=2, bias=True)\n",
    "            Parameter containing:\n",
    "            tensor([[ 1.,  1.],\n",
    "                    [ 1.,  1.]])\n",
    "            Sequential(\n",
    "              (0): Linear(in_features=2, out_features=2, bias=True)\n",
    "              (1): Linear(in_features=2, out_features=2, bias=True)\n",
    "            )\n",
    "            Sequential(\n",
    "              (0): Linear(in_features=2, out_features=2, bias=True)\n",
    "              (1): Linear(in_features=2, out_features=2, bias=True)\n",
    "            )\n",
    "        \"\"\"\n",
    "        for module in self.children():\n",
    "            module.apply(fn)\n",
    "        fn(self)\n",
    "        return self\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31b5a07",
   "metadata": {},
   "source": [
    "### bfloat16\n",
    "\n",
    "将网络参数中的浮点类型参数转换成bfloat16类型。注意只会将float类型转换成bfloat16类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0b8b0",
   "metadata": {},
   "source": [
    "### buffers\n",
    "\n",
    "网络参数中的附属统计量，比如均值，方差等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcec545",
   "metadata": {},
   "source": [
    "### cpu\n",
    "\n",
    "将模型所有的参数和buffers移到CPU上去。\n",
    "\n",
    "```python\n",
    "def cpu(self: T) -> T:\n",
    "        r\"\"\"Moves all model parameters and buffers to the CPU.\n",
    "        .. note::\n",
    "            This method modifies the module in-place.\n",
    "        Returns:\n",
    "            Module: self\n",
    "        \"\"\"\n",
    "        return self._apply(lambda t: t.cpu())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba7e5f8",
   "metadata": {},
   "source": [
    "### cuda\n",
    "\n",
    "将模型所有的参数和buffers移到GPU上去。\n",
    "\n",
    "```python\n",
    "def cuda(self: T, device: Optional[Union[int, device]] = None) -> T:\n",
    "        r\"\"\"Moves all model parameters and buffers to the GPU.\n",
    "        This also makes associated parameters and buffers different objects. So\n",
    "        it should be called before constructing optimizer if the module will\n",
    "        live on GPU while being optimized.\n",
    "        .. note::\n",
    "            This method modifies the module in-place.\n",
    "        Args:\n",
    "            device (int, optional): if specified, all parameters will be\n",
    "                copied to that device\n",
    "        Returns:\n",
    "            Module: self\n",
    "        \"\"\"\n",
    "        return self._apply(lambda t: t.cuda(device))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e685b6",
   "metadata": {},
   "source": [
    "### eval\n",
    "\n",
    "将模型设置为evaluation模式，这个主要是会去影响像dropout和batchnorm这些模块的具体影响上。\n",
    "\n",
    "其源代码中其实就是将self.training设置为False。\n",
    "\n",
    "```python\n",
    "def eval(self: T) -> T:\n",
    "        r\"\"\"Sets the module in evaluation mode.\n",
    "        This has any effect only on certain modules. See documentations of\n",
    "        particular modules for details of their behaviors in training/evaluation\n",
    "        mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
    "        etc.\n",
    "        This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
    "        See :ref:`locally-disable-grad-doc` for a comparison between\n",
    "        `.eval()` and several similar mechanisms that may be confused with it.\n",
    "        Returns:\n",
    "            Module: self\n",
    "        \"\"\"\n",
    "        return self.train(False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea528bbf",
   "metadata": {},
   "source": [
    "### get_parameter\n",
    "\n",
    "依据`target`来去得到模型里面的参数。\n",
    "\n",
    "```python\n",
    "def get_parameter(self, target: str) -> \"Parameter\":\n",
    "        \"\"\"\n",
    "        Returns the parameter given by ``target`` if it exists,\n",
    "        otherwise throws an error.\n",
    "        See the docstring for ``get_submodule`` for a more detailed\n",
    "        explanation of this method's functionality as well as how to\n",
    "        correctly specify ``target``.\n",
    "        Args:\n",
    "            target: The fully-qualified string name of the Parameter\n",
    "                to look for. (See ``get_submodule`` for how to specify a\n",
    "                fully-qualified string.)\n",
    "        Returns:\n",
    "            torch.nn.Parameter: The Parameter referenced by ``target``\n",
    "        Raises:\n",
    "            AttributeError: If the target string references an invalid\n",
    "                path or resolves to something that is not an\n",
    "                ``nn.Parameter``\n",
    "        \"\"\"\n",
    "        module_path, _, param_name = target.rpartition(\".\")\n",
    "\n",
    "        mod: torch.nn.Module = self.get_submodule(module_path)\n",
    "\n",
    "        if not hasattr(mod, param_name):\n",
    "            raise AttributeError(mod._get_name() + \" has no attribute `\"\n",
    "                                 + param_name + \"`\")\n",
    "\n",
    "        param: torch.nn.Parameter = getattr(mod, param_name)\n",
    "\n",
    "        if not isinstance(param, torch.nn.Parameter):\n",
    "            raise AttributeError(\"`\" + param_name + \"` is not an \"\n",
    "                                 \"nn.Parameter\")\n",
    "\n",
    "        return param\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a485552",
   "metadata": {},
   "source": [
    "### get_submodule\n",
    "\n",
    "依据target去得到子模块，submodule。依据给定的字符串，去获取到一个子module。\n",
    "\n",
    "```python\n",
    "def get_submodule(self, target: str) -> \"Module\":\n",
    "        \"\"\"\n",
    "        Returns the submodule given by ``target`` if it exists,\n",
    "        otherwise throws an error.\n",
    "        For example, let's say you have an ``nn.Module`` ``A`` that\n",
    "        looks like this:\n",
    "        .. code-block::text\n",
    "            A(\n",
    "                (net_b): Module(\n",
    "                    (net_c): Module(\n",
    "                        (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
    "                    )\n",
    "                    (linear): Linear(in_features=100, out_features=200, bias=True)\n",
    "                )\n",
    "            )\n",
    "        (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
    "        submodule ``net_b``, which itself has two submodules ``net_c``\n",
    "        and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
    "        To check whether or not we have the ``linear`` submodule, we\n",
    "        would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
    "        we have the ``conv`` submodule, we would call\n",
    "        ``get_submodule(\"net_b.net_c.conv\")``.\n",
    "        The runtime of ``get_submodule`` is bounded by the degree\n",
    "        of module nesting in ``target``. A query against\n",
    "        ``named_modules`` achieves the same result, but it is O(N) in\n",
    "        the number of transitive modules. So, for a simple check to see\n",
    "        if some submodule exists, ``get_submodule`` should always be\n",
    "        used.\n",
    "        Args:\n",
    "            target: The fully-qualified string name of the submodule\n",
    "                to look for. (See above example for how to specify a\n",
    "                fully-qualified string.)\n",
    "        Returns:\n",
    "            torch.nn.Module: The submodule referenced by ``target``\n",
    "        Raises:\n",
    "            AttributeError: If the target string references an invalid\n",
    "                path or resolves to something that is not an\n",
    "                ``nn.Module``\n",
    "        \"\"\"\n",
    "        if target == \"\":\n",
    "            return self\n",
    "\n",
    "        atoms: List[str] = target.split(\".\")\n",
    "        mod: torch.nn.Module = self\n",
    "\n",
    "        for item in atoms:\n",
    "\n",
    "            if not hasattr(mod, item):\n",
    "                raise AttributeError(mod._get_name() + \" has no \"\n",
    "                                     \"attribute `\" + item + \"`\")\n",
    "\n",
    "            mod = getattr(mod, item)\n",
    "\n",
    "            if not isinstance(mod, torch.nn.Module):\n",
    "                raise AttributeError(\"`\" + item + \"` is not \"\n",
    "                                     \"an nn.Module\")\n",
    "\n",
    "        return mod\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318a72e",
   "metadata": {},
   "source": [
    "### state_dict\n",
    "\n",
    "返回一个字典，包含一整个module的state。\n",
    "\n",
    "```python\n",
    "def state_dict(self, destination=None, prefix='', keep_vars=False):\n",
    "        r\"\"\"Returns a dictionary containing a whole state of the module.\n",
    "        Both parameters and persistent buffers (e.g. running averages) are\n",
    "        included. Keys are corresponding parameter and buffer names.\n",
    "        Parameters and buffers set to ``None`` are not included.\n",
    "        Returns:\n",
    "            dict:\n",
    "                a dictionary containing a whole state of the module\n",
    "        Example::\n",
    "            >>> module.state_dict().keys()\n",
    "            ['bias', 'weight']\n",
    "        \"\"\"\n",
    "        if destination is None:\n",
    "            destination = OrderedDict()\n",
    "            destination._metadata = OrderedDict()\n",
    "        destination._metadata[prefix[:-1]] = local_metadata = dict(version=self._version)\n",
    "        self._save_to_state_dict(destination, prefix, keep_vars)\n",
    "        for name, module in self._modules.items():\n",
    "            if module is not None:\n",
    "                module.state_dict(destination, prefix + name + '.', keep_vars=keep_vars)\n",
    "        for hook in self._state_dict_hooks.values():\n",
    "            hook_result = hook(self, destination, prefix, local_metadata)\n",
    "            if hook_result is not None:\n",
    "                destination = hook_result\n",
    "        return destination\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214f19c",
   "metadata": {},
   "source": [
    "### load_state_dict\n",
    "\n",
    "从state_dict中去拷贝模型的参数到module中去。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc941cd0",
   "metadata": {},
   "source": [
    "### named_parameters\n",
    "\n",
    "返回module的所有参数，包括他的名称和参数具体的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7332a13",
   "metadata": {},
   "source": [
    "### requires_grad_(requires_grad=True)\n",
    "\n",
    "这个方法主要是设置module中的parameters是否需要进行自动参数更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c503040",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "在Module的init方法中，有设置self.training = True，这个参数有在Dropout源码中用到：\n",
    "\n",
    "- [https://pytorch.org/docs/stable/_modules/torch/nn/modules/dropout.html#Dropout](https://pytorch.org/docs/stable/_modules/torch/nn/modules/dropout.html#Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526c3ab",
   "metadata": {},
   "source": [
    "```python\n",
    "class _DropoutNd(Module):\n",
    "    __constants__ = ['p', 'inplace']\n",
    "    p: float\n",
    "    inplace: bool\n",
    "\n",
    "    def __init__(self, p: float = 0.5, inplace: bool = False) -> None:\n",
    "        super(_DropoutNd, self).__init__()\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(\"dropout probability has to be between 0 and 1, \"\n",
    "                             \"but got {}\".format(p))\n",
    "        self.p = p\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'p={}, inplace={}'.format(self.p, self.inplace)\n",
    "\n",
    "\n",
    "class Dropout(_DropoutNd):\n",
    "    r\"\"\"During training, randomly zeroes some of the elements of the input\n",
    "    tensor with probability :attr:`p` using samples from a Bernoulli\n",
    "    distribution. Each channel will be zeroed out independently on every forward\n",
    "    call.\n",
    "\n",
    "    This has proven to be an effective technique for regularization and\n",
    "    preventing the co-adaptation of neurons as described in the paper\n",
    "    `Improving neural networks by preventing co-adaptation of feature\n",
    "    detectors`_ .\n",
    "\n",
    "    Furthermore, the outputs are scaled by a factor of :math:`\\frac{1}{1-p}` during\n",
    "    training. This means that during evaluation the module simply computes an\n",
    "    identity function.\n",
    "\n",
    "    Args:\n",
    "        p: probability of an element to be zeroed. Default: 0.5\n",
    "        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(*)`. Input can be of any shape\n",
    "        - Output: :math:`(*)`. Output is of the same shape as input\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> m = nn.Dropout(p=0.2)\n",
    "        >>> input = torch.randn(20, 16)\n",
    "        >>> output = m(input)\n",
    "\n",
    "    .. _Improving neural networks by preventing co-adaptation of feature\n",
    "        detectors: https://arxiv.org/abs/1207.0580\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return F.dropout(input, self.p, self.training, self.inplace)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dff765",
   "metadata": {},
   "source": [
    "## 容器\n",
    "\n",
    "- [https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/container.py](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/container.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71302777",
   "metadata": {},
   "source": [
    "### Sequential\n",
    "\n",
    "Sequential容器是一个有序的，当往Sequential中放入模块的时候，放入的顺序就是就是神经网络模块堆叠的顺序。其官方给定的创建方式有两种：\n",
    "\n",
    "```python\n",
    "model = nn.Sequential(\n",
    "                  nn.Conv2d(1,20,5),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(20,64,5),\n",
    "                  nn.ReLU()\n",
    "                )\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "          ('conv1', nn.Conv2d(1,20,5)),\n",
    "          ('relu1', nn.ReLU()),\n",
    "          ('conv2', nn.Conv2d(20,64,5)),\n",
    "          ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf53b7",
   "metadata": {},
   "source": [
    "在Sequential这个类中，其init方法源码如下：\n",
    "\n",
    "```python\n",
    "def __init__(self, *args):\n",
    "    super(Sequential, self).__init__()\n",
    "    if len(args) == 1 and isinstance(args[0], OrderedDict):\n",
    "        for key, module in args[0].items():\n",
    "            self.add_module(key, module)\n",
    "    else:\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "```\n",
    "\n",
    "可以看到如果是给定的OrderdDict类的话，key就是指定的OrderdDict中的key。不然的话，key就是给定的module的索引。\n",
    "\n",
    "其forward函数源码如下：\n",
    "\n",
    "```python\n",
    "def forward(self, input):\n",
    "    for module in self:\n",
    "        input = module(input)\n",
    "    return \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e245b3",
   "metadata": {},
   "source": [
    "### ModuleList\n",
    "\n",
    "ModuleList中是可以将多个子Module放到一个列表中。源码中给的例子如下：\n",
    "\n",
    "```python\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
    "    def forward(self, x):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = self.linears[i // 2](x) + l(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "`class ModuleList(Module)`类的init方法如下：\n",
    "\n",
    "```python\n",
    "def __init__(self, modules: Optional[Iterable[Module]] = None) -> None:\n",
    "    super(ModuleList, self).__init__()\n",
    "    if modules is not None:\n",
    "        self += modules\n",
    "```\n",
    "\n",
    "可以看到，它是将modules添加到它自身self中去的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeaa7aa",
   "metadata": {},
   "source": [
    "### ModuleDict\n",
    "\n",
    "ModuleDict是另外一种构建网络模型的方式。源码中给定的例子是：\n",
    "\n",
    "```python\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.choices = nn.ModuleDict({\n",
    "                'conv': nn.Conv2d(10, 10, 3),\n",
    "                'pool': nn.MaxPool2d(3)\n",
    "        })\n",
    "        self.activations = nn.ModuleDict([\n",
    "                ['lrelu', nn.LeakyReLU()],\n",
    "                ['prelu', nn.PReLU()]\n",
    "        ])\n",
    "    def forward(self, x, choice, act):\n",
    "        x = self.choices[choice](x)\n",
    "        x = self.activations[act](x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "class ModuleDict(Module)类中的init源码如下：\n",
    "\n",
    "```python\n",
    "def __init__(self, modules: Optional[Mapping[str, Module]] = None) -> None:\n",
    "    super(ModuleDict, self).__init__()\n",
    "    if modules is not None:\n",
    "        self.update(modules)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77543a6",
   "metadata": {},
   "source": [
    "### ParameterList\n",
    "\n",
    "ParameterList也是Module的一个子类。官方源码给定的示例为：\n",
    "\n",
    "```python\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])\n",
    "    def forward(self, x):\n",
    "        # ParameterList can act as an iterable, or be indexed using ints\n",
    "        for i, p in enumerate(self.params):\n",
    "            x = self.params[i // 2].mm(x) + p.mm(x)\n",
    "        return x\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec253bf9",
   "metadata": {},
   "source": [
    "### ParameterDict\n",
    "\n",
    "ParameterDict同样是Module的一个子类。官方源码给定的示例为：\n",
    "\n",
    "```python\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "                'left': nn.Parameter(torch.randn(5, 10)),\n",
    "                'right': nn.Parameter(torch.randn(5, 10))\n",
    "        })\n",
    "    def forward(self, x, choice):\n",
    "        x = self.params[choice].mm(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8701e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f995a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
