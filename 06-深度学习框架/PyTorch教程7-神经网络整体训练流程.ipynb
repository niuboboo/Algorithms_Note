{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b55660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d212edc7",
   "metadata": {},
   "source": [
    "## 处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed996a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tinyzqh/miniforge3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-wdh4qigd/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "training_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab1ce0",
   "metadata": {},
   "source": [
    "## 构建网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6f6af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c3332",
   "metadata": {},
   "source": [
    "## 训练逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b7241",
   "metadata": {},
   "source": [
    "### 给定超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6707f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 1e-3\n",
    "batch_size= 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e65c8",
   "metadata": {},
   "source": [
    "### 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b23dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ab0a9",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57eeeeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9b01a",
   "metadata": {},
   "source": [
    "### 训练和测试函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10156285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        # 计算前向传播和损失函数。\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 计算反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), batch_idx * len(X)\n",
    "            print(\"loss: {}, [{} / {}]\".format(loss, current, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129aa456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\"Test Error \\n Accuracy {}%, Avg loss {}\".format(100 * correct, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f6c54",
   "metadata": {},
   "source": [
    "### 训练总逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c03b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " ---------------------\n",
      "loss: 2.3066787719726562, [0 / 60000]\n",
      "loss: 2.293390989303589, [6400 / 60000]\n",
      "loss: 2.2809338569641113, [12800 / 60000]\n",
      "loss: 2.274946689605713, [19200 / 60000]\n",
      "loss: 2.2548093795776367, [25600 / 60000]\n",
      "loss: 2.236323833465576, [32000 / 60000]\n",
      "loss: 2.236793041229248, [38400 / 60000]\n",
      "loss: 2.2117464542388916, [44800 / 60000]\n",
      "loss: 2.2048537731170654, [51200 / 60000]\n",
      "loss: 2.1832661628723145, [57600 / 60000]\n",
      "Test Error \n",
      " Accuracy 49.43%, Avg loss 2.177778518883286\n",
      "Epoch 1\n",
      " ---------------------\n",
      "loss: 2.188567638397217, [0 / 60000]\n",
      "loss: 2.1802597045898438, [6400 / 60000]\n",
      "loss: 2.132342576980591, [12800 / 60000]\n",
      "loss: 2.147294759750366, [19200 / 60000]\n",
      "loss: 2.095224618911743, [25600 / 60000]\n",
      "loss: 2.051515817642212, [32000 / 60000]\n",
      "loss: 2.072225570678711, [38400 / 60000]\n",
      "loss: 2.005096435546875, [44800 / 60000]\n",
      "loss: 2.000612497329712, [51200 / 60000]\n",
      "loss: 1.9464870691299438, [57600 / 60000]\n",
      "Test Error \n",
      " Accuracy 55.400000000000006%, Avg loss 1.9414378359059619\n",
      "Epoch 2\n",
      " ---------------------\n",
      "loss: 1.9732542037963867, [0 / 60000]\n",
      "loss: 1.9490618705749512, [6400 / 60000]\n",
      "loss: 1.839998722076416, [12800 / 60000]\n",
      "loss: 1.877785086631775, [19200 / 60000]\n",
      "loss: 1.7637332677841187, [25600 / 60000]\n",
      "loss: 1.7194271087646484, [32000 / 60000]\n",
      "loss: 1.7379003763198853, [38400 / 60000]\n",
      "loss: 1.6364837884902954, [44800 / 60000]\n",
      "loss: 1.6555097103118896, [51200 / 60000]\n",
      "loss: 1.5593377351760864, [57600 / 60000]\n",
      "Test Error \n",
      " Accuracy 58.89%, Avg loss 1.5684555245053238\n",
      "Epoch 3\n",
      " ---------------------\n",
      "loss: 1.6408307552337646, [0 / 60000]\n",
      "loss: 1.602603793144226, [6400 / 60000]\n",
      "loss: 1.4486281871795654, [12800 / 60000]\n",
      "loss: 1.5208988189697266, [19200 / 60000]\n",
      "loss: 1.3894245624542236, [25600 / 60000]\n",
      "loss: 1.386942982673645, [32000 / 60000]\n",
      "loss: 1.3986704349517822, [38400 / 60000]\n",
      "loss: 1.317924976348877, [44800 / 60000]\n",
      "loss: 1.3511865139007568, [51200 / 60000]\n",
      "loss: 1.2576196193695068, [57600 / 60000]\n",
      "Test Error \n",
      " Accuracy 62.19%, Avg loss 1.2784067012701825\n",
      "Epoch 4\n",
      " ---------------------\n",
      "loss: 1.3670638799667358, [0 / 60000]\n",
      "loss: 1.341342806816101, [6400 / 60000]\n",
      "loss: 1.1730693578720093, [12800 / 60000]\n",
      "loss: 1.2793306112289429, [19200 / 60000]\n",
      "loss: 1.147552490234375, [25600 / 60000]\n",
      "loss: 1.1772236824035645, [32000 / 60000]\n",
      "loss: 1.191886067390442, [38400 / 60000]\n",
      "loss: 1.1267551183700562, [44800 / 60000]\n",
      "loss: 1.1634273529052734, [51200 / 60000]\n",
      "loss: 1.0890547037124634, [57600 / 60000]\n",
      "Test Error \n",
      " Accuracy 63.73%, Avg loss 1.1042993763449844\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(\"Epoch {}\\n ---------------------\".format(t))\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08a6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
