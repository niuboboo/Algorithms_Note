{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efc1735",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab6f5a",
   "metadata": {},
   "source": [
    "- [https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebee57",
   "metadata": {},
   "source": [
    "nn.Module是所有神经网络的Base Class，我们自己编写的模型应该继承自这个基础类。Modules应该包含其它的Modules。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0840eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a2f960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc446a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f9e021c",
   "metadata": {},
   "source": [
    "## 源码解析\n",
    "\n",
    "- [https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47dd152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07644cb2",
   "metadata": {},
   "source": [
    "### init方法\n",
    "\n",
    "主要的类是`class Module:`类，其init方法的源码如下：\n",
    "\n",
    "```python\n",
    "def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
    "        \"\"\"\n",
    "        torch._C._log_api_usage_once(\"python.nn_module\")\n",
    "\n",
    "        self.training = True\n",
    "        self._parameters: Dict[str, Optional[Parameter]] = OrderedDict()\n",
    "        self._buffers: Dict[str, Optional[Tensor]] = OrderedDict()\n",
    "        self._non_persistent_buffers_set: Set[str] = set()\n",
    "        self._backward_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._is_full_backward_hook = None\n",
    "        self._forward_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._forward_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._state_dict_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._load_state_dict_pre_hooks: Dict[int, Callable] = OrderedDict()\n",
    "        self._modules: Dict[str, Optional['Module']] = OrderedDict()\n",
    "```\n",
    "\n",
    "可以看到里面有很多成员变量，大部分是字典的形式。默认情况下training=True，也就是batchnorm，dropout都是遵循training=True这种设定的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989ed52",
   "metadata": {},
   "source": [
    "### register_buffer\n",
    "\n",
    "register_buffer方法的函数源码如下，是将buffer注册到module中去。参数有name，tensor和persistent。\n",
    "\n",
    "```python\n",
    "def register_buffer(self, name: str, tensor: Optional[Tensor], persistent: bool = True) -> None:\n",
    "        r\"\"\"Adds a buffer to the module.\n",
    "        This is typically used to register a buffer that should not to be\n",
    "        considered a model parameter. For example, BatchNorm's ``running_mean``\n",
    "        is not a parameter, but is part of the module's state. Buffers, by\n",
    "        default, are persistent and will be saved alongside parameters. This\n",
    "        behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
    "        only difference between a persistent buffer and a non-persistent buffer\n",
    "        is that the latter will not be a part of this module's\n",
    "        :attr:`state_dict`.\n",
    "        Buffers can be accessed as attributes using given names.\n",
    "        Args:\n",
    "            name (string): name of the buffer. The buffer can be accessed\n",
    "                from this module using the given name\n",
    "            tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
    "                that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
    "                the buffer is **not** included in the module's :attr:`state_dict`.\n",
    "            persistent (bool): whether the buffer is part of this module's\n",
    "                :attr:`state_dict`.\n",
    "        Example::\n",
    "            >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        \"\"\"\n",
    "        if persistent is False and isinstance(self, torch.jit.ScriptModule):\n",
    "            raise RuntimeError(\"ScriptModule does not support non-persistent buffers\")\n",
    "\n",
    "        if '_buffers' not in self.__dict__:\n",
    "            raise AttributeError(\n",
    "                \"cannot assign buffer before Module.__init__() call\")\n",
    "        elif not isinstance(name, torch._six.string_classes):\n",
    "            raise TypeError(\"buffer name should be a string. \"\n",
    "                            \"Got {}\".format(torch.typename(name)))\n",
    "        elif '.' in name:\n",
    "            raise KeyError(\"buffer name can't contain \\\".\\\"\")\n",
    "        elif name == '':\n",
    "            raise KeyError(\"buffer name can't be empty string \\\"\\\"\")\n",
    "        elif hasattr(self, name) and name not in self._buffers:\n",
    "            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
    "        elif tensor is not None and not isinstance(tensor, torch.Tensor):\n",
    "            raise TypeError(\"cannot assign '{}' object to buffer '{}' \"\n",
    "                            \"(torch Tensor or None required)\"\n",
    "                            .format(torch.typename(tensor), name))\n",
    "        else:\n",
    "            self._buffers[name] = tensor\n",
    "            if persistent:\n",
    "                self._non_persistent_buffers_set.discard(name)\n",
    "            else:\n",
    "                self._non_persistent_buffers_set.add(name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf0d46",
   "metadata": {},
   "source": [
    "### register_parameter\n",
    "\n",
    "register_parameter是一个比register_buffer更加常用的一个方法。参数有name，和param两个。其源代码如下所示：\n",
    "\n",
    "```python\n",
    "def register_parameter(self, name: str, param: Optional[Parameter]) -> None:\n",
    "        r\"\"\"Adds a parameter to the module.\n",
    "        The parameter can be accessed as an attribute using given name.\n",
    "        Args:\n",
    "            name (string): name of the parameter. The parameter can be accessed\n",
    "                from this module using the given name\n",
    "            param (Parameter or None): parameter to be added to the module. If\n",
    "                ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
    "                are ignored. If ``None``, the parameter is **not** included in the\n",
    "                module's :attr:`state_dict`.\n",
    "        \"\"\"\n",
    "        if '_parameters' not in self.__dict__:\n",
    "            raise AttributeError(\n",
    "                \"cannot assign parameter before Module.__init__() call\")\n",
    "\n",
    "        elif not isinstance(name, torch._six.string_classes):\n",
    "            raise TypeError(\"parameter name should be a string. \"\n",
    "                            \"Got {}\".format(torch.typename(name)))\n",
    "        elif '.' in name:\n",
    "            raise KeyError(\"parameter name can't contain \\\".\\\"\")\n",
    "        elif name == '':\n",
    "            raise KeyError(\"parameter name can't be empty string \\\"\\\"\")\n",
    "        elif hasattr(self, name) and name not in self._parameters:\n",
    "            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
    "\n",
    "        if param is None:\n",
    "            self._parameters[name] = None\n",
    "        elif not isinstance(param, Parameter):\n",
    "            raise TypeError(\"cannot assign '{}' object to parameter '{}' \"\n",
    "                            \"(torch.nn.Parameter or None required)\"\n",
    "                            .format(torch.typename(param), name))\n",
    "        elif param.grad_fn:\n",
    "            raise ValueError(\n",
    "                \"Cannot assign non-leaf Tensor to parameter '{0}'. Model \"\n",
    "                \"parameters must be created explicitly. To express '{0}' \"\n",
    "                \"as a function of another Tensor, compute the value in \"\n",
    "                \"the forward() method.\".format(name))\n",
    "        else:\n",
    "            self._parameters[name] = param\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2559dc",
   "metadata": {},
   "source": [
    "### add_module方法\n",
    "\n",
    "函数原型为：\n",
    "\n",
    "```python\n",
    "add_module(name, module)\n",
    "```\n",
    "\n",
    "通过`add_module`方法，我们可以将子`module`添加到当前的`module`中去。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee46e73",
   "metadata": {},
   "source": [
    "### children\n",
    "\n",
    "返回可以迭代的子模块。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103032d",
   "metadata": {},
   "source": [
    "### apply方法\n",
    "\n",
    "apply是以一个函数作为一个参数，可以将函数递归地作用到子模块中去。这些子模块是能够通过.children()返回得到的子模块。通常用来初始化模型的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4701d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f998c608",
   "metadata": {},
   "source": [
    "### bfloat16\n",
    "\n",
    "将网络参数中的浮点类型参数转换成bfloat16类型。注意只会将float类型转换成bfloat16类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45f9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab7b19c7",
   "metadata": {},
   "source": [
    "### buffers\n",
    "\n",
    "网络参数中的附属统计量，比如均值，方差等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f730ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afe91133",
   "metadata": {},
   "source": [
    "### cpu\n",
    "\n",
    "将模型所有的参数和buffers移到CPU上去。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba615848",
   "metadata": {},
   "source": [
    "### cuda\n",
    "\n",
    "将模型所有的参数和buffers移到GPU上去。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21bbdd",
   "metadata": {},
   "source": [
    "### eval\n",
    "\n",
    "将模型设置为evaluation模式，这个主要是会去影响像dropout和batchnorm这些模块的具体影响上。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd57862",
   "metadata": {},
   "source": [
    "### get_parameter\n",
    "\n",
    "依据target来去得到模型里面的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a404d7cb",
   "metadata": {},
   "source": [
    "### get_submodule\n",
    "\n",
    "依据target去得到子模块，submodule。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6163fc",
   "metadata": {},
   "source": [
    "### state_dict\n",
    "\n",
    "返回一个字典，包含一整个module的state。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4203f755",
   "metadata": {},
   "source": [
    "### load_state_dict\n",
    "\n",
    "从state_dict中去拷贝模型的参数到module中去。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9079ac",
   "metadata": {},
   "source": [
    "### named_parameters\n",
    "\n",
    "返回module的所有参数，包括他的名称和参数具体的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8cdd7",
   "metadata": {},
   "source": [
    "### requires_grad_(requires_grad=True)\n",
    "\n",
    "这个方法主要是设置module中的parameters是否需要进行自动参数更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88360917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad445a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d487ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
