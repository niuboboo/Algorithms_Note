{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d94ce8",
   "metadata": {},
   "source": [
    "## 游戏简介\n",
    "\n",
    "捕食者游戏说的是: 在一个固定的区域内，有三个对象，玩家，食物和敌人。玩家需要在不碰到敌人的情况下，找到食物。如果碰到了敌人就会被敌人吃掉。拿到食物即为胜利，被敌人吃掉的话就输了。\n",
    "\n",
    "- 原文链接: https://pythonprogramming.net/q-learning-reinforcement-learning-python-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba9851",
   "metadata": {},
   "source": [
    "## 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cca6fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/tinyzqh/miniforge3/lib/python3.9/site-packages (4.5.5.62)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/tinyzqh/miniforge3/lib/python3.9/site-packages (from opencv-python) (1.22.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b160ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/tinyzqh/miniforge3/lib/python3.9/site-packages (8.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d2aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9491fb",
   "metadata": {},
   "source": [
    "## 环境类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa95fc",
   "metadata": {},
   "source": [
    "### 游戏主体对象实例化\n",
    "\n",
    "在这个游戏中，会创建不同的实体，像食物food，玩家player和敌人enemy。他们都是在二维方格中的一个点，因此它们会有两个属性。x坐标和y坐标。\n",
    "\n",
    "每个实体具备移动的属性，可以往x轴和y轴的任意方向移动。因此定义了如下函数:\n",
    "\n",
    "```python\n",
    "def move(self, x=False, y=False):\n",
    "```\n",
    "\n",
    "如果指定x和y移动多少，就按照指定的x和y进行移动。否者就随机进行移动。但是要注意是否移动出了边界，如果移动出了边界的话，就返回的是边界值。因此，在初始化的时候，我们需要指定地图的大小size。\n",
    "\n",
    "进一步将move封装为action，抽象化为九个可选动作，函数原型如下:\n",
    "\n",
    "```python\n",
    "def action(self, choise):\n",
    "```\n",
    "\n",
    "最后我们还需要打印两个实体的位置信息，定义函数原型如下:\n",
    "\n",
    "```python\n",
    "def __str__(self):\n",
    "    \"\"\"打印这个实体的时候，如何显示\"\"\"\n",
    "    return \"x : {}, y : {}\".format(self.x, self.y)\n",
    "```\n",
    "\n",
    "判断两个实体的相对位置:\n",
    "\n",
    "```python\n",
    "def __sub__(self, other):\n",
    "    \"\"\"位置间隔多少，通过一个减的操作实现\"\"\"\n",
    "    return (self.x - other.x, self.y - other.y)\n",
    "```\n",
    "\n",
    "判断两个实体是否相等:\n",
    "\n",
    "```python\n",
    "def __eq__(self, other):\n",
    "    \"\"\"判断两个实例是否是相等的\"\"\"\n",
    "    return self.x == other.x and self.y == other.y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183f3368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cube(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.x = np.random.randint(0, size)  # 智能体的初始位置\n",
    "        self.y = np.random.randint(0, size)  # 智能体的初始位置\n",
    "        \n",
    "    def action(self, choise):\n",
    "        if choise == 0:\n",
    "            self.move(x=1, y=1)\n",
    "        elif choise == 1:\n",
    "            self.move(x=-1, y=1)\n",
    "        elif choise == 2:\n",
    "            self.move(x=1, y=-1)\n",
    "        elif choise == 3:\n",
    "            self.move(x=-1, y=-1)\n",
    "        elif choise == 4:\n",
    "            self.move(x=0, y=1)\n",
    "        elif choise == 5:\n",
    "            self.move(x=0, y=-1)\n",
    "        elif choise == 6:\n",
    "            self.move(x=1, y=0)\n",
    "        elif choise == 7:\n",
    "            self.move(x=-1, y=0)\n",
    "        elif choise == 8:  # 原地不动。\n",
    "            self.move(x=0, y=0)\n",
    "        else:\n",
    "            print(\"ERROR ACTION!\")\n",
    "    \n",
    "    def move(self, x=False, y=False):\n",
    "        \"\"\"x, y为给定的位置\"\"\"\n",
    "        if not x:  # 如果没有给定x，就给一个随机的值，随机值属于【-1， 0， 1】\n",
    "            self.x += np.random.randint(-1, 2)\n",
    "        else:\n",
    "            self.x += x\n",
    "        \n",
    "        if not y:  # 如果没有给定y，就给一个随机的值，随机值属于【-1， 0， 1】\n",
    "            self.y += np.random.randint(-1, 2)\n",
    "        else:\n",
    "            self.y += y\n",
    "        \n",
    "        if self.x < 0:  # 走出了边界，则赋值为0\n",
    "            self.x = 0\n",
    "        elif self.x >= self.size:\n",
    "            self.x = self.size - 1\n",
    "        \n",
    "        if self.y < 0:  # 走出了边界，则赋值为0\n",
    "            self.y = 0\n",
    "        elif self.y >= self.size:\n",
    "            self.y = self.size - 1\n",
    "            \n",
    "    def __str__(self):\n",
    "        \"\"\"打印这个实体的时候，如何显示\"\"\"\n",
    "        return \"x : {}, y : {}\".format(self.x, self.y)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \"\"\"位置间隔多少，通过一个减的操作实现\"\"\"\n",
    "        return (self.x - other.x, self.y - other.y)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \"\"\"判断两个实例是否是相等的\"\"\"\n",
    "        return self.x == other.x and self.y == other.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af480a2",
   "metadata": {},
   "source": [
    "### 环境实例化\n",
    "\n",
    "在能够实例化游戏主体对象时，我们就可以构造类似`gym`的游戏环境了。游戏环境中的核心方法有四个:\n",
    "\n",
    "1. `def __init__(self):` 设置环境初始化的一些信息。\n",
    "2. `def reset(self):`  重启环境的一些设定\n",
    "3. `def step(self, action):` 实现环境的状态转移\n",
    "4. `def render(self):` 对环境进行一个实时的渲染\n",
    "\n",
    "通常在初始化的时候，我们需要调用`gym.spaces`中的方法来创建动作空间和状态空间。\n",
    "\n",
    "`gym.spaces`的源码地址: https://github.com/openai/gym/tree/master/gym/spaces\n",
    "\n",
    "- `Box`方法创建的方法有两种：\n",
    "\n",
    "1. 对于每个维度都是相同的边界值\n",
    "\n",
    "```bash\n",
    ">>> Box(low=-1.0, high=2.0, shape=(3, 4), dtype=np.float32)\n",
    "Box(3, 4)\n",
    "```\n",
    "\n",
    "2. 对于每个维度是不同的边界值\n",
    "\n",
    "```bash\n",
    ">>> Box(low=np.array([-1.0, -2.0]), high=np.array([2.0, 4.0]), dtype=np.float32)\n",
    "Box(2,)\n",
    "```\n",
    "其中dtype定义的是空间中的数据类型。\n",
    "\n",
    "- `Discrete`方法主要是创建一个离散的空间，从0到n-1。\n",
    "\n",
    "例如:\n",
    "\n",
    "```bash\n",
    ">>> Discrete(2)\n",
    ">>> Discrete(3, start=-1)  # {-1, 0, 1}\n",
    "```\n",
    "\n",
    "通过这种创建方式，我们就可以调用其内部的一些方法，比如像sample采样方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef1f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "class CubeEnv(Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.MapSize = 10  # 地图大小\n",
    "        self.ActionSpace = Discrete(9)\n",
    "        # self.ActionSpace = Box(low=0, high=9, shape=(1,), dtype=np.int32) # 返回numpy数据类型。\n",
    "        self.ObservationSpace = Box(low=-9, high=9, shape=(1, 4), dtype=np.int32)\n",
    "        \n",
    "        self.ReturnImage = False  # 是否返回图像。\n",
    "    \n",
    "        self.FoodReward = 25  # 食物的奖励是25分。\n",
    "        self.EnemyReward = -300  # 遇到敌人的惩罚是-300分。\n",
    "        self.MoveReward = -1  # 移动惩罚为-1分。\n",
    "\n",
    "        self.d = {1:(255, 0, 0),  # blue\n",
    "                 2:(0, 255, 0),  # green\n",
    "                 3:(0, 0, 255)}  # red\n",
    "\n",
    "        self.PlayerNum = 1  # 玩家为1号颜色\n",
    "        self.FoodNum = 2 # 食物为2号颜色\n",
    "        self.EnemyNum = 3 # 敌人为3号颜色\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        self.player = Cube(self.MapSize)\n",
    "        \n",
    "        self.food = Cube(self.MapSize)\n",
    "        while self.food == self.player:  # 当玩家位置与食物位置相同时，重新生成一遍。\n",
    "            self.food = Cube(self.MapSize)\n",
    "            \n",
    "        self.enemy = Cube(self.MapSize)\n",
    "        while self.enemy == self.food or self.enemy == self.player:  # 当敌人与食物或者玩家重叠时，重新生成一遍敌人。\n",
    "            self.enemy = Cube(self.MapSize)\n",
    "        \n",
    "        if self.ReturnImage:\n",
    "            obs = np.array(self.get_image())\n",
    "        else:\n",
    "            obs = (self.player - self.food) + (self.player - self.enemy)\n",
    "        \n",
    "        self.episode_step = 0 # 游戏step数清零。\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.episode_step += 1\n",
    "        \n",
    "        self.player.action(action)\n",
    "        self.food.move() # 食物随机移动一下\n",
    "        self.enemy.move() # 敌人也随机移动一下\n",
    "        \n",
    "        if self.ReturnImage:\n",
    "            # 如果需要返回图像的话，就将地图所有信息返回\n",
    "            new_obs = np.array(self.get_image())\n",
    "        else:\n",
    "            # 返回坐标之间的相对位置\n",
    "            new_obs = (self.player - self.food) + (self.player - self.enemy)\n",
    "        \n",
    "        if self.player == self.food:\n",
    "            reward = self.FoodReward\n",
    "        elif self.player == self.enemy:\n",
    "            reward = self.EnemyReward\n",
    "        else:\n",
    "            reward = self.MoveReward\n",
    "            \n",
    "        done = False\n",
    "        if self.player == self.food or self.player == self.enemy or self.episode_step >= 200:\n",
    "            done = True\n",
    "            \n",
    "        return new_obs, reward, done\n",
    "    \n",
    "    def render(self):\n",
    "        img = self.get_image()\n",
    "        img = img.resize((800, 800))\n",
    "        cv2.imshow('', np.array(img))\n",
    "        cv2.waitKey(50)\n",
    "        \n",
    "    def get_image(self):\n",
    "        env = np.zeros((self.MapSize, self.MapSize, 3), dtype=np.uint8)\n",
    "        env[self.food.x][self.food.y] = self.d[self.FoodNum]\n",
    "        env[self.player.x][self.player.y] = self.d[self.PlayerNum]\n",
    "        env[self.enemy.x][self.enemy.y] = self.d[self.EnemyNum]\n",
    "        img = Image.fromarray(env, \"RGB\")  # 展示游戏界面\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831d45a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CubeEnv()\n",
    "env.ObservationSpace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde8148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.ActionSpace.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d870c",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada8ef7",
   "metadata": {},
   "source": [
    "$$\n",
    "Q^{\\text {new }}\\left(s_{t}, a_{t}\\right) \\leftarrow(1-\\alpha) \\cdot \\underbrace{Q\\left(s_{t}, a_{t}\\right)}_{\\text {old value }}+\\underbrace{\\alpha}_{\\text {learning rate }} \\cdot \\overbrace{(\\underbrace{r_{t}}_{\\text {reward }}+\\underbrace{\\gamma}_{\\text {discount factor }} \\cdot \\underbrace{\\max _{a} Q\\left(s_{t+1}, a\\right)}_{\\text {estimate of optimal future value }})}^{\\text {learned value }}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58826663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning(object):\n",
    "    def __init__(self, Env, LearningRate, Gamma, QTableName=None):\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        # 参数env: 可用于获取状态和动作空间的大小。\n",
    "        # 参数QTableName: QTableName表示Q表文件名的地址，默认为None。\n",
    "        # 参数LearningRate: 表示Q-Learning的学习率。\n",
    "        # 参数Gamma: 表示折扣因子。\n",
    "        \"\"\"\n",
    "        self.env = Env\n",
    "        self.QTableName = QTableName\n",
    "        self.lr = LearningRate\n",
    "        self.gamma = Gamma\n",
    "        \n",
    "        self.ActionSpaceValues = env.ActionSpace.n  # 获取动作空间维度的大小。\n",
    "        self.ObsSpaceValues = env.ObservationSpace.shape  # 获取状态空间维度的大小。\n",
    "        self.MapSize = env.MapSize # 获取地图维度的大小。\n",
    "        \n",
    "        self.InitQTable()  # 调用初始化q table函数初始化q table\n",
    "    \n",
    "    def InitQTable(self):\n",
    "        \"\"\"初始化Q Table\"\"\"\n",
    "        \n",
    "        if self.QTableName is None:  # Q Table不存在，将要进行随机初始化\n",
    "            self.q_table = {}\n",
    "            # q_table的每个状态范围是从-9到9的, 共19个变量。状态空间维度为4, 所以状态之间的组合有19的四次方种。\n",
    "            for x1 in range(- self.MapSize + 1, self.MapSize):  # 玩家与食物之间的x轴距离。\n",
    "                for y1 in range(- self.MapSize + 1, self.MapSize):  # 玩家与食物之间的y轴的距离。\n",
    "                    for x2 in range(- self.MapSize + 1, self.MapSize):  # 玩家与敌人之间的x轴的距离。\n",
    "                        for y2 in range(- self.MapSize + 1, self.MapSize):  # 玩家与敌人之间的y轴的距离。\n",
    "                            self.q_table[(x1, y1, x2, y2)] = [np.random.uniform(-5, 0) \n",
    "                                                             for i in range(self.ActionSpaceValues)]\n",
    "        else:  # 存在，将其从文件中加载进来\n",
    "            with open(self.QTableName, 'rb') as f:\n",
    "                self.q_table = pickle.load(f)\n",
    "        \n",
    "    \n",
    "    def UpdateQTable(self, Obs, Action, Reward, NextObs):\n",
    "        \"\"\"\n",
    "        更新 Q Table\n",
    "        # 参数Obs表示当前的观测。\n",
    "        # 参数Action表示当前观测下选择的实际动作。\n",
    "        # 参数Reward表示当前观测下，执行实际选择的动作所获的的奖励。\n",
    "        # 参数NextObs表示，执行完Action转移到的下一个状态。\n",
    "        \"\"\"\n",
    "        \n",
    "        old_q = self.q_table[obs][action]  # 从QTable中索引，获取到当前的Q值。\n",
    "        \n",
    "        # 如果已经迟到了食物，那么游戏会结束，下一个状态的Q值就是即时奖励。否则，就需要依据Q-Leaning的公式做更新计算。\n",
    "        if Reward == self.env.FoodReward:\n",
    "            new_q = Reward\n",
    "        else:\n",
    "            new_q = old_q + self.lr * (Reward + self.gamma * max(self.q_table[NextObs]) - old_q)\n",
    "        \n",
    "        self.q_table[obs][action] = new_q  # 将QTable中old Q进行更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fdf08c",
   "metadata": {},
   "source": [
    "## Q-Learning的训练主循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18937d45",
   "metadata": {},
   "source": [
    "### 训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3201301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 30000 # 智能体要玩这个游戏的局数为30000。\n",
    "ShowEvery = 3000 # 每隔3000局展示一下当前局状况。\n",
    "Epsilon = 0.6 # 百分之六十的随机动作，百分之四十的最大价值动作。\n",
    "EpsDecay = 0.9998 # 随机动作减少的折扣数，每玩一局游戏，Epsilon减少EpsDecay多倍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609f66a",
   "metadata": {},
   "source": [
    "### 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53ce610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tinyzqh/miniforge3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/tinyzqh/miniforge3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, epsilon 0.6, mean reward nan\n",
      "episode 3000, epsilon 0.32926722239570905, mean reward nan\n",
      "episode 6000, epsilon 0.18069483957364205, mean reward -138.88766666666666\n",
      "episode 9000, epsilon 0.09916147987941909, mean reward -123.47533333333334\n",
      "episode 12000, epsilon 0.054417708414240505, mean reward -108.96133333333333\n",
      "episode 15000, epsilon 0.029863279497827713, mean reward -97.28658333333334\n",
      "episode 18000, epsilon 0.016388331819794114, mean reward -88.9928\n",
      "episode 21000, epsilon 0.00899356749667138, mean reward -82.41227777777777\n",
      "episode 24000, epsilon 0.00493547831509555, mean reward -76.95776190476191\n",
      "episode 27000, epsilon 0.0027084853933429503, mean reward -72.14758333333333\n"
     ]
    }
   ],
   "source": [
    "env = CubeEnv()\n",
    "agent = QLearning(Env=env, LearningRate=0.1, Gamma=0.95, QTableName=None)\n",
    "\n",
    "episode_rewards = []\n",
    "\n",
    "for episode in range(Episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    \n",
    "    # 隔ShowEvery步打印并展示结果。\n",
    "    if episode % ShowEvery == 0:\n",
    "        print(\"episode {}, epsilon {}, mean reward {}\".format(episode, \n",
    "                                                              Epsilon, np.mean(episode_rewards[ShowEvery:])))\n",
    "        show = True\n",
    "    else:\n",
    "        show = False\n",
    "    \n",
    "    while not done:  # 如果当前这局游戏没有结束\n",
    "        \n",
    "        if np.random.random() > Epsilon:\n",
    "            action = np.argmax(agent.q_table[obs])\n",
    "        else:\n",
    "            action = np.random.randint(0, env.ActionSpace.n)\n",
    "        \n",
    "        next_obs, reward, done = env.step(action)\n",
    "        \n",
    "        # 更新Agent中的Q table。\n",
    "        agent.UpdateQTable(Obs=obs, Action=action, Reward=reward, NextObs=next_obs)\n",
    "        \n",
    "        # 更新当前观测\n",
    "        obs = next_obs\n",
    "        \n",
    "        if show:\n",
    "            env.render()\n",
    "        \n",
    "        episode_reward += reward\n",
    "            \n",
    "    episode_rewards.append(episode_reward)\n",
    "    Epsilon *= EpsDecay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cc532",
   "metadata": {},
   "source": [
    "## 绘图展示奖励曲线\n",
    "\n",
    "为了直观查看智能体的学习过程，我们通常绘制其奖励曲线。这里采用`np.convolve()`方法对奖励曲线进行滤波处理。`np.convolve()`方法原理解释如下:\n",
    "\n",
    "\n",
    "```bash\n",
    ">>>np.convolve([3, 8, 10, 9, 11, 23, 44, 55, 57, 48], np.ones((3,))/3, mode='valid')\n",
    "array([ 7.        ,  9.        , 10.        , 14.33333333, 26.        ,\n",
    "    40.66666667, 52.        , 53.33333333])\n",
    "```\n",
    "\n",
    "可以看到它是将前3个的值取了平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e98c2748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "moving_avg = np.convolve(episode_rewards, np.ones(ShowEvery,)/ShowEvery, mode='valid')\n",
    "print(len(moving_avg))\n",
    "plt.plot([i for i in range(len(moving_avg))], moving_avg)\n",
    "plt.xlabel('episode')\n",
    "plt.ylabel('mean {} reward'.format(ShowEvery))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb967e",
   "metadata": {},
   "source": [
    "## 测试智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb1ea615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent, episodes, show_enable):\n",
    "    env = CubeEnv()\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        episode_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = np.argmax(agent.q_table[obs])\n",
    "            obs, reward, done = env.step(action=action)\n",
    "            if show_enable == True:\n",
    "                env.render()\n",
    "            \n",
    "            episode_reward += reward\n",
    "        \n",
    "        print(\"episode {}, episode_reward {}\".format(episode, episode_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7cbbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, episode_reward 16\n",
      "episode 1, episode_reward -8\n",
      "episode 2, episode_reward -20\n",
      "episode 3, episode_reward 7\n",
      "episode 4, episode_reward 16\n",
      "episode 5, episode_reward -90\n",
      "episode 6, episode_reward -14\n",
      "episode 7, episode_reward 7\n",
      "episode 8, episode_reward 25\n",
      "episode 9, episode_reward -55\n"
     ]
    }
   ],
   "source": [
    "test(agent=agent, episodes=10, show_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0b9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207978e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc1f849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4cc5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f8785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56ed08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad7baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
