{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6573fe",
   "metadata": {},
   "source": [
    "## 策略迭代\n",
    "\n",
    "策略迭代分为两步:\n",
    "\n",
    "<img src=\"../../images/11-policy-iteratioin.png\" width=\"50%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf7bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa9e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8f1c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315200 sweeps of state space in policy evaluation\n",
      "-536.69\t-537.05\t-536.40\t-534.36\t-531.20\t-527.49\t-523.95\t-521.19\t-519.69\t\n",
      "\n",
      "-532.33\t-534.06\t-533.80\t-531.48\t-527.73\t-523.34\t-519.15\t-515.93\t-514.19\t\n",
      "\n",
      "-530.56\t-529.07\t-529.25\t-526.04\t-520.91\t-514.99\t-509.40\t-505.17\t-502.96\t\n",
      "\n",
      "-526.27\t-526.72\t-524.08\t-518.51\t-510.86\t-502.31\t-494.30\t-488.38\t-485.53\t\n",
      "\n",
      "-525.86\t-523.46\t-517.86\t-509.07\t-497.73\t-485.08\t-473.13\t-464.52\t-461.24\t\n",
      "\n",
      "-523.83\t-519.41\t-510.81\t-498.17\t-481.90\t-463.16\t-444.60\t-431.32\t-429.67\t\n",
      "\n",
      "-522.24\t-515.53\t-503.81\t-486.91\t-464.55\t-437.05\t-406.78\t-382.51\t-392.46\t\n",
      "\n",
      "-519.18\t-512.68\t-497.98\t-477.09\t-448.34\t-409.72\t-358.96\t-295.47\t-230.31\t\n",
      "\n",
      "-518.61\t-509.88\t-494.33\t-471.14\t-438.01\t-390.53\t-319.87\t-206.12\t0.00\t\n",
      "\n",
      "--------------------\n",
      "80 sweeps of state space in policy evaluation\n",
      "80 sweeps of state space in policy improvement\n",
      "1200 sweeps of state space in policy evaluation\n",
      "80 sweeps of state space in policy improvement\n",
      "-11.00\t-12.00\t-13.00\t-12.00\t-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t\n",
      "\n",
      "-10.00\t-11.00\t-12.00\t-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t\n",
      "\n",
      "-11.00\t-10.00\t-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t\n",
      "\n",
      "-10.00\t-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t\n",
      "\n",
      "-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t\n",
      "\n",
      "-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t-2.00\t\n",
      "\n",
      "-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t-2.00\t-1.00\t\n",
      "\n",
      "-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t-2.00\t-1.00\t0.00\t\n",
      "\n",
      "-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t-2.00\t-1.00\t0.00\t0.00\t\n",
      "\n",
      "--------------------\n",
      "['D']\t['D']\t['D']\t['R']\t['R']\t['D']\t['D']\t['D']\t['D']\t\n",
      "\n",
      "['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t\n",
      "\n",
      "--\t['L']\t['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t\n",
      "\n",
      "['U']\t['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t['D']\t\n",
      "\n",
      "['R']\t['R']\t['R']\t['R']\t['D']\t['D']\t['D']\t['D']\t['D']\t\n",
      "\n",
      "['R']\t['R']\t['R']\t['R']\t['R']\t['D']\t['D']\t['D']\t['D']\t\n",
      "\n",
      "['R']\t['R']\t['R']\t['R']\t['R']\t['R']\t['D']\t['D']\t['D']\t\n",
      "\n",
      "--\t['R']\t['R']\t['R']\t['R']\t['R']\t['R']\t['D']\t['D']\t\n",
      "\n",
      "['R']\t['R']\t['R']\t['R']\t['R']\t['R']\t['R']\t['R']\t--\t\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GridWorld(object):\n",
    "    def __init__(self, m, n, magicSquares):\n",
    "        self.grid = np.zeros((m,n))\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.stateSpace = [i for i in range(self.m*self.n)]\n",
    "        self.stateSpace.remove(80)\n",
    "        self.stateSpacePlus = [i for i in range(self.m*self.n)]\n",
    "        self.possibleActions = ['U', 'D', 'L', 'R']\n",
    "        self.actionSpace = {'U': -self.m, 'D': self.m,'L': -1, 'R': 1}\n",
    "        self.P = {}  # 用一个字典存储状态转移矩阵。\n",
    "        # dict with magic squares and resulting squares\n",
    "        self.magicSquares = magicSquares\n",
    "        self.initP()\n",
    "\n",
    "    def initP(self):\n",
    "        for state in self.stateSpace:\n",
    "            for action in self.possibleActions:\n",
    "                reward = -1\n",
    "                state_ = state + self.actionSpace[action]\n",
    "                if state_ in self.magicSquares.keys():  # 如果state在magicSquares中，就进行跳转。\n",
    "                    state_ = self.magicSquares[state_]\n",
    "                if self.offGridMove(state_, state):\n",
    "                    state_ = state\n",
    "                    \n",
    "                if self.isTerminalState(state_):\n",
    "                    reward = 0\n",
    "                    \n",
    "                self.P[(state_, reward, state, action)] = 1\n",
    "\n",
    "    def isTerminalState(self, state):\n",
    "        return state in self.stateSpacePlus and state not in self.stateSpace\n",
    "\n",
    "    def offGridMove(self, newState, oldState):\n",
    "        # if we move into a row not in the grid\n",
    "        if newState not in self.stateSpacePlus:\n",
    "            return True\n",
    "        # if we're trying to wrap around to next row\n",
    "        elif oldState % self.m == 0 and newState  % self.m == self.m - 1:\n",
    "            return True\n",
    "        elif oldState % self.m == self.m - 1 and newState % self.m == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def printV(V, grid):\n",
    "    for idx, row in enumerate(grid.grid):\n",
    "        for idy, _ in enumerate(row):\n",
    "            state = grid.m * idx + idy\n",
    "            print('%.2f' % V[state], end='\\t')\n",
    "        print('\\n')\n",
    "    print('--------------------')\n",
    "\n",
    "def printPolicy(policy, grid):\n",
    "    for idx, row in enumerate(grid.grid):\n",
    "        for idy, _ in enumerate(row):\n",
    "            state = grid.m * idx + idy\n",
    "            if not grid.isTerminalState(state):\n",
    "                if state not in grid.magicSquares.keys():\n",
    "                    print('%s' % policy[state], end='\\t')\n",
    "                else:\n",
    "                    print('%s' % '--', end='\\t')\n",
    "            else:\n",
    "                print('%s' % '--', end='\\t')\n",
    "        print('\\n')\n",
    "    print('--------------------')\n",
    "\n",
    "def evaluatePolicy(grid, V, policy, GAMMA, THETA):\n",
    "    # policy evaluation for the random choice in gridworld\n",
    "    converged = False\n",
    "    i = 0\n",
    "    while not converged:\n",
    "        DELTA = 0\n",
    "        for state in grid.stateSpace:\n",
    "            i += 1\n",
    "            oldV = V[state]\n",
    "            total = 0\n",
    "            weight = 1 / len(policy[state])\n",
    "            for action in policy[state]:\n",
    "                for key in grid.P:\n",
    "                    (newState, reward, oldState, act) = key\n",
    "                    # We're given state and action, want new state and reward\n",
    "                    if oldState == state and act == action:\n",
    "                        total += weight*grid.P[key]*(reward+GAMMA*V[newState])\n",
    "            V[state] = total\n",
    "            DELTA = max(DELTA, np.abs(oldV-V[state]))\n",
    "            converged = True if DELTA < THETA else False\n",
    "    print(i, 'sweeps of state space in policy evaluation')\n",
    "    return V\n",
    "\n",
    "def improvePolicy(grid, V, policy, GAMMA):\n",
    "    stable = True\n",
    "    newPolicy = {}\n",
    "    i = 0\n",
    "    for state in grid.stateSpace:\n",
    "        i += 1\n",
    "        oldActions = policy[state]\n",
    "        value = []\n",
    "        newAction = []\n",
    "        for action in policy[state]:\n",
    "            weight = 1 / len(policy[state])\n",
    "            for key in grid.P:\n",
    "                (newState, reward, oldState, act) = key\n",
    "                # We're given state and action, want new state and reward\n",
    "                if oldState == state and act == action:\n",
    "                    value.append(np.round(weight*grid.P[key]*(reward+GAMMA*V[newState]), 2))\n",
    "                    newAction.append(action)\n",
    "        value = np.array(value)\n",
    "        best = np.where(value == value.max())[0]\n",
    "        bestActions = [newAction[item] for item in best]\n",
    "        newPolicy[state] = bestActions\n",
    "\n",
    "        if oldActions != bestActions:\n",
    "            stable = False\n",
    "    print(i, 'sweeps of state space in policy improvement')\n",
    "    return stable, newPolicy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # map magic squares to their connecting square\n",
    "    magicSquares = {18: 54, 63: 14}\n",
    "    env = GridWorld(9, 9, magicSquares)\n",
    "    # model hyperparameters\n",
    "    GAMMA = 1.0\n",
    "    THETA = 1e-6 # convergence criteria\n",
    "\n",
    "    V = {}\n",
    "    for state in env.stateSpacePlus:\n",
    "        V[state] = 0\n",
    "\n",
    "    policy = {}\n",
    "    for state in env.stateSpace:\n",
    "        # equiprobable random strategy\n",
    "        policy[state] = env.possibleActions\n",
    "\n",
    "    V = evaluatePolicy(env, V, policy, GAMMA, THETA)\n",
    "    printV(V, env)\n",
    "\n",
    "    stable = False\n",
    "    while not stable:\n",
    "        V = evaluatePolicy(env, V, policy, GAMMA, THETA)\n",
    "\n",
    "        stable, policy = improvePolicy(env, V, policy, GAMMA)\n",
    "\n",
    "    printV(V, env)\n",
    "\n",
    "    printPolicy(policy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66195119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
