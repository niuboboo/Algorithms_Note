{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2418f715",
   "metadata": {},
   "source": [
    "## 值迭代\n",
    "\n",
    "&emsp;&emsp;值迭代的算法伪代码如下所示:\n",
    "\n",
    "<img src=\"../images/11-value_iteration.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75fd500",
   "metadata": {},
   "source": [
    "首先是可以用任意值初始化值估计$V$。然后去更新值估计，最后当值估计收敛到一个比较小的值之后，我们就退出循环，将寻找最大的值估计作为我们的最终策略输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda7c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b21f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2097a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4693ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld(object):\n",
    "    def __init__(self, m, n, magicSquares):\n",
    "        self.grid = np.zeros((m,n))\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.stateSpace = [i for i in range(self.m*self.n)]\n",
    "        self.stateSpace.remove(self.m * self.n -1)\n",
    "        self.stateSpacePlus = [i for i in range(self.m*self.n)]\n",
    "        self.possibleActions = ['U', 'D', 'L', 'R']\n",
    "        self.actionSpace = {'U': -self.m, 'D': self.m, 'L': -1, 'R': 1}\n",
    "        self.P = {}\n",
    "        # dict with magic squares and resulting squares\n",
    "        self.magicSquares = magicSquares\n",
    "        self.initP()\n",
    "\n",
    "    def initP(self):\n",
    "        for state in self.stateSpace:\n",
    "            for action in self.possibleActions:\n",
    "                reward = -1\n",
    "                state_ = state + self.actionSpace[action]\n",
    "                if state_ in self.magicSquares.keys():\n",
    "                    state_ = self.magicSquares[state_]\n",
    "                if self.offGridMove(state_, state):\n",
    "                    state_ = state\n",
    "                if self.isTerminalState(state_):\n",
    "                    reward = 0\n",
    "                self.P[(state_, reward, state, action)] = 1\n",
    "\n",
    "    def isTerminalState(self, state):\n",
    "        return state in self.stateSpacePlus and state not in self.stateSpace\n",
    "\n",
    "    def offGridMove(self, newState, oldState):\n",
    "        # if we move into a row not in the grid\n",
    "        if newState not in self.stateSpacePlus:\n",
    "            return True\n",
    "        # if we're trying to wrap around to next row\n",
    "        elif oldState % self.n == 0 and newState  % self.n == self.n - 1:\n",
    "            return True\n",
    "        elif oldState % self.n == self.n - 1 and newState % self.n == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cfab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 sweeps of state space for value iteration\n",
      "160 sweeps of state space for value iteration\n",
      "-11.00\t-12.00\t-13.00\t-12.00\t-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t\n",
      "\n",
      "-10.00\t-11.00\t-12.00\t-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t\n",
      "\n",
      "-11.00\t-10.00\t-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t\n",
      "\n",
      "-10.00\t-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t\n",
      "\n",
      "-11.00\t-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t\n",
      "\n",
      "-10.00\t-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t-2.00\t\n",
      "\n",
      "-9.00\t-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t-2.00\t-1.00\t\n",
      "\n",
      "-8.00\t-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t-2.00\t-1.00\t0.00\t\n",
      "\n",
      "-7.00\t-6.00\t-5.00\t-4.00\t-3.00\t-2.00\t-1.00\t0.00\t0.00\t\n",
      "\n",
      "--------------------\n",
      "D\tD\tD\tD\tD\tD\tD\tD\tD\t\n",
      "\n",
      "D\tD\tD\tD\tD\tD\tD\tD\tD\t\n",
      "\n",
      "--\tL\tD\tD\tD\tD\tD\tD\tD\t\n",
      "\n",
      "U\tU\tD\tD\tD\tD\tD\tD\tD\t\n",
      "\n",
      "U\tD\tD\tD\tD\tD\tD\tD\tD\t\n",
      "\n",
      "D\tD\tD\tD\tD\tD\tD\tD\tD\t\n",
      "\n",
      "R\tD\tD\tD\tD\tD\tD\tD\tD\t\n",
      "\n",
      "--\tD\tD\tD\tD\tD\tD\tD\tD\t\n",
      "\n",
      "R\tR\tR\tR\tR\tR\tR\tR\t--\t\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def printV(V, grid):\n",
    "    for idx, row in enumerate(grid.grid):\n",
    "        for idy, _ in enumerate(row):\n",
    "            state = grid.m * idx + idy\n",
    "            print('%.2f' % V[state], end='\\t')\n",
    "        print('\\n')\n",
    "    print('--------------------')\n",
    "\n",
    "def printPolicy(policy, grid):\n",
    "    for idx, row in enumerate(grid.grid):\n",
    "        for idy, _ in enumerate(row):\n",
    "            state = grid.m * idx + idy\n",
    "            if not grid.isTerminalState(state):\n",
    "                if state not in grid.magicSquares.keys():\n",
    "                    print('%s' % policy[state], end='\\t')\n",
    "                else:\n",
    "                    print('%s' % '--', end='\\t')\n",
    "            else:\n",
    "                print('%s' % '--', end='\\t')\n",
    "        print('\\n')\n",
    "    print('--------------------')\n",
    "\n",
    "\n",
    "def iterateValues(grid, V, policy, GAMMA, THETA):\n",
    "    converged = False  # 设置收敛判断条件\n",
    "    i = 0\n",
    "    while not converged:\n",
    "        DELTA = 0\n",
    "        for state in grid.stateSpace:\n",
    "            i += 1\n",
    "            oldV = V[state]  # 记录一下old state。\n",
    "            newV = []\n",
    "            for action in grid.actionSpace:\n",
    "                for key in grid.P:\n",
    "                    (newState, reward, oldState, act) = key  # 解压key\n",
    "                    if state == oldState and action == act:\n",
    "                        newV.append(grid.P[key]*(reward+GAMMA*V[newState]))\n",
    "            newV = np.array(newV)\n",
    "            bestV = np.where(newV == newV.max())[0]\n",
    "            bestState = np.random.choice(bestV)\n",
    "            V[state] = newV[bestState]\n",
    "            DELTA = max(DELTA, np.abs(oldV-V[state]))\n",
    "            converged = True if DELTA < THETA else False\n",
    "\n",
    "    for state in grid.stateSpace:\n",
    "        newValues = []\n",
    "        actions = []\n",
    "        i += 1\n",
    "        for action in grid.actionSpace:\n",
    "            for key in grid.P:\n",
    "                (newState, reward, oldState, act) = key\n",
    "                if state == oldState and action == act:\n",
    "                    newValues.append(grid.P[key]*(reward+GAMMA*V[newState]))\n",
    "            actions.append(action)\n",
    "        newValues = np.array(newValues)\n",
    "        bestActionIDX = np.where(newValues == newValues.max())[0]\n",
    "        bestActions = actions[bestActionIDX[0]]\n",
    "        policy[state] = bestActions\n",
    "    print(i, 'sweeps of state space for value iteration')\n",
    "    return V, policy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # map magic squares to their connecting square\n",
    "    magicSquares = {18: 54, 63: 14}\n",
    "    env = GridWorld(9, 9, magicSquares)\n",
    "    # model hyperparameters\n",
    "    GAMMA = 1.0\n",
    "    THETA = 1e-6 # convergence criteria\n",
    "\n",
    "    V = {}  # 初始化状态值函数为0\n",
    "    for state in env.stateSpacePlus:\n",
    "        V[state] = 0\n",
    "\n",
    "    policy = {}  # 初始化策略为等概率策略\n",
    "    for state in env.stateSpace:\n",
    "        # equiprobable random strategy\n",
    "        policy[state] = env.possibleActions\n",
    "\n",
    "    # 2 round of value iteration ftw\n",
    "    for i in range(2):\n",
    "        V, policy = iterateValues(env, V, policy, GAMMA, THETA)\n",
    "\n",
    "    printV(V, env)\n",
    "    printPolicy(policy, env)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55c9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
